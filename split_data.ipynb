{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for splitting data into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your local\n",
    "ROOT_DIR = \"/home/andreasabo/Documents/HNProject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_to_split_on = \"at_least_one_target_and_labelled_view\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(ROOT_DIR, \"all_label_df.csv\")\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9581 from 230 scans from 71 patients in this dataframe.\n",
      "Index(['Unnamed: 0', 'num_in_seq', 'function_label', 'image_ids', 'image_manu',\n",
      "       'reflux_label', 'surgery_label', 'view_label', 'subj_id', 'scan_num',\n",
      "       'image_num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the df of images we want to consider as the entire dataset\n",
    "if data_set_to_split_on == \"at_least_one_target_and_labelled_view\":\n",
    "    labelled_view_df = df[(df.view_label != \"Missing\") & (df.view_label != \"Other\")]\n",
    "    frame_to_split = labelled_view_df[(labelled_view_df.function_label != \"Missing\") | (labelled_view_df.reflux_label != \"Missing\") | (labelled_view_df.surgery_label != \"Missing\")]\n",
    "elif 0: # Replace this with other datasets as we define them\n",
    "    pass\n",
    "else:\n",
    "    raise Exception(\"Invalid data to split on!\")\n",
    "\n",
    "\n",
    "# Some QA to make sure the dataset we are using is what we expect it to be\n",
    "frame_to_split_count = frame_to_split.groupby('subj_id').scan_num.agg(['nunique'])\n",
    "print(f\"There are {len(frame_to_split)} from {frame_to_split_count['nunique'].sum()} scans from {frame_to_split.subj_id.nunique()} patients in this dataframe.\")\n",
    "print(frame_to_split.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_count                   9581.0\n",
      "img_percent_count              1.0\n",
      "Philips Medical Systems     5119.0\n",
      "TOSHIBA_MEC                 3599.0\n",
      "ATL                          260.0\n",
      "ACUSON                       219.0\n",
      "SAMSUNG MEDISON CO.,LTD.     133.0\n",
      "TOSHIBA_MEC_US               125.0\n",
      "GE Medical Systems            83.0\n",
      "GE Healthcare                 43.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add image counts and percentage of total images that belong to each patient\n",
    "patient_scan_details = frame_to_split.groupby('subj_id').image_num.agg(img_count='count')\n",
    "patient_scan_details['img_percent_count'] = patient_scan_details['img_count'] / patient_scan_details['img_count'].sum()\n",
    "\n",
    "# Calculate percent (of all images) that were taken by each machine for each patient \n",
    "machine_labels = dict(frame_to_split['image_manu'].value_counts())\n",
    "for machine in machine_labels:\n",
    "    this_machine = frame_to_split[frame_to_split['image_manu'] == machine]\n",
    "    this_machine_count = this_machine.groupby('subj_id').image_manu.count()\n",
    "#     patient_scan_details[\"percent_\" + machine] = this_machine.groupby('subj_id').image_manu.count() / len(frame_to_split)\n",
    "    patient_scan_details[machine] = this_machine.groupby('subj_id').image_manu.count()\n",
    "\n",
    "# Replace nans with 0s because they're easier to work with\n",
    "patient_scan_details = patient_scan_details.fillna(0)\n",
    "print(patient_scan_details.sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04976092829317003 13047\n"
     ]
    }
   ],
   "source": [
    "def calculate_scanner_proportion_diff(patient_scan_details, train, test):\n",
    "    train_machine_counts = patient_scan_details[patient_scan_details.index.isin(train)]\n",
    "    test_machine_counts = patient_scan_details[patient_scan_details.index.isin(test)]\n",
    "\n",
    "    proportions_test = test_machine_counts.sum(axis=0) / test_machine_counts['img_count'].sum()\n",
    "    proportions_train = train_machine_counts.sum(axis=0) / train_machine_counts['img_count'].sum()\n",
    "    diff = abs(proportions_train - proportions_test)\n",
    "    \n",
    "    return diff.sum()\n",
    "\n",
    "\n",
    "def select_split(df, patient_scan_details, test_percentage=0.2, num_trials=25000):\n",
    "    lowest_diff = 100\n",
    "    lowest_diff_seed = 0\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        patients = df.subj_id.unique()\n",
    "        train, test = train_test_split(patients, test_size=test_percentage, random_state=i)\n",
    "        cur_diff = calculate_scanner_proportion_diff(patient_scan_details, train, test)\n",
    "        if cur_diff < lowest_diff:\n",
    "            lowest_diff = cur_diff\n",
    "            lowest_diff_seed = i\n",
    "            \n",
    "    print(lowest_diff, lowest_diff_seed)\n",
    "    \n",
    "    # Split on the best state we found\n",
    "    train, test = train_test_split(patients, test_size=test_percentage, random_state=lowest_diff_seed)\n",
    "    cur_diff = calculate_scanner_proportion_diff(patient_scan_details, train, test)\n",
    "    \n",
    "    return train, test\n",
    "    \n",
    "    \n",
    "train_subjs, test_subjs = select_split(frame_to_split, patient_scan_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths_to_img(dataset, image_dir):\n",
    "    filepaths = pd.DataFrame()\n",
    "    filepaths['paths'] = image_dir + dataset['subj_id'].map(str) + \"_\" + dataset['scan_num'].map(str) + \"_\" + dataset['image_num'].map(str) + \".jpg\" \n",
    "    return filepaths\n",
    "\n",
    "\n",
    "def split_data_based_on_patients(df_to_split, image_dir, train_ids, test_ids):\n",
    "    train_set = df_to_split[df_to_split.subj_id.isin(train_ids)]\n",
    "    test_set = df_to_split[df_to_split.subj_id.isin(test_ids)]\n",
    "    \n",
    "    train_filepaths = get_filepaths_to_img(train_set, image_dir)\n",
    "    test_filepaths = get_filepaths_to_img(test_set, image_dir)\n",
    "\n",
    "    return train_filepaths, test_filepaths\n",
    "    \n",
    "train_filepaths, test_filepaths = split_data_based_on_patients(frame_to_split, os.path.join(ROOT_DIR, 'all_label_img/'), train_subjs, test_subjs)  \n",
    "\n",
    "train_filepaths.to_csv(os.path.join(ROOT_DIR, 'train_filepaths.csv'))\n",
    "test_filepaths.to_csv(os.path.join(ROOT_DIR, 'test_filepaths.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
