{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZbZRovgc-In"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from torch.utils import data\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import io\n",
    "import uuid\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import wandb\n",
    "wandb_username = 'denizjafari'\n",
    "local_username = 'denizjafari'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2aVSXNyc-Iv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1') \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylfRtoN9c-Iy"
   },
   "outputs": [],
   "source": [
    "# root directory\n",
    "root_dir = \"/home/andreasabo/Documents/HNProject/\"\n",
    "split_file_base = \"/home/andreasabo/Documents/HNUltra/\"\n",
    "\n",
    "# data directory on current machine: abhishekmoturu, andreasabo, denizjafari, navidkorhani\n",
    "data_dir = \"/home/\" + local_username + \"/Documents/HNProject/all_label_img/\"\n",
    "\n",
    "# read target df\n",
    "csv_path = os.path.join(root_dir, \"all_splits_1000000.csv\")\n",
    "data_df = pd.read_csv(csv_path, usecols=['subj_id', 'image_ids', 'view_label', 'view_train'])\n",
    "\n",
    "# Are we doing the final test?\n",
    "test_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_OCR_7uy52w"
   },
   "source": [
    "### **Reading Data Indicies and Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nnwavxcqGBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading splits from file\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'Other':0, 'Saggital_Right':1, 'Transverse_Right':2, \n",
    "                 'Saggital_Left':3, 'Transverse_Left':4, 'Bladder':5}\n",
    "label_unmapping = {0: 'Other', 1:'Saggital_Right', 2: 'Transverse_Right', \n",
    "                   3:'Saggital_Left', 4:'Transverse_Left', 5: 'Bladder'}\n",
    "\n",
    "data_df['view_label'] = data_df['view_label'].map(label_mapping)\n",
    "\n",
    "train_df = data_df[data_df.view_train == 1]\n",
    "test_df = data_df[data_df.view_train == 0]\n",
    "\n",
    "unique_subj = train_df.subj_id.unique()\n",
    "\n",
    "# Create the splits for 5-fold cross validation based on subj_id\n",
    "data_split_file = split_file_base + 'data_splits.json'\n",
    "# just load from file\n",
    "print(\"Reading splits from file\")\n",
    "with open(data_split_file, 'r') as f:\n",
    "    all_folds = json.load(f)\n",
    "\n",
    "# If we're testing, overwrite the training data with the entire train/test data\n",
    "if test_data:\n",
    "    train_images = train_df.image_ids.tolist()\n",
    "    test_images = test_df.image_ids.tolist()\n",
    "    train_labels = train_df.view_label.tolist()\n",
    "    test_labels = test_df.view_label.tolist()\n",
    "\n",
    "    cur_fold = {'train_ids': train_images, 'test_ids': test_images, 'train_labels': train_labels, 'test_labels': test_labels}\n",
    "\n",
    "    \n",
    "    all_folds['test'] = cur_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13958\n",
      "11081\n",
      "5070\n",
      "2877\n"
     ]
    }
   ],
   "source": [
    "print(len(all_folds['test']['train_ids']))\n",
    "print(len(all_folds['0']['train_ids']))\n",
    "\n",
    "print(len(all_folds['test']['test_ids']))\n",
    "print(len(all_folds['0']['valid_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DIRECTORIES \n",
    "\n",
    "\n",
    "vae50_dir = '/home/navidkorhani/Documents/HNProject/HNUltra/saved models/vae_model_h800_l50.pt'\n",
    "vae100_dir = \"/home/navidkorhani/Documents/HNProject/HNUltra/results/h800_l100_e30/vae_model.pt\"\n",
    "vae200_dir = \"/home/navidkorhani/Documents/HNProject/HNUltra/results/h800_l200_e30/vae_model.pt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbgEWoqKc-JO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == 'vae50':\n",
    "        \n",
    "        model_ft = VAE_50()\n",
    "        input_size = 256\n",
    "        \n",
    "    elif model_name == 'vae100':\n",
    "        \n",
    "        model_ft = VAE_100()\n",
    "        input_size = 256\n",
    "        \n",
    "    elif model_name == 'vae200':\n",
    "        \n",
    "        model_ft = VAE_200()\n",
    "        input_size = 256\n",
    "        \n",
    "        \n",
    "    elif model_name == 'viewnet':\n",
    "        conv1_filters = 8\n",
    "        conv2_filters = 16\n",
    "        conv3_filters = 32\n",
    "        linear1_size = 512\n",
    "        dropout = 0.25\n",
    "        model_ft = ViewNet(num_classes, conv1_filters, conv2_filters, conv3_filters, linear1_size, dropout)\n",
    "        input_size = 256\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Architectures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom view labeller \n",
    "class ViewNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, conv1_filters, conv2_filters, conv3_filters, linear1_size, dropout):\n",
    "        super(ViewNet, self).__init__()\n",
    "        self.conv1_filters = conv1_filters\n",
    "        self.conv2_filters = conv2_filters\n",
    "        self.conv3_filters = conv3_filters\n",
    "        self.linear1_size = linear1_size\n",
    "        self.drop_percent = dropout\n",
    "        self.max_pool = 4\n",
    "        self.conv_output = int(self.conv3_filters*(256/(self.max_pool**3))*(256/(self.max_pool**3)))\n",
    "        print(\"conv_output: \", self.conv_output)\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, self.conv1_filters, 4, padding=2)\n",
    "        self.conv2 = nn.Conv2d(self.conv1_filters, self.conv2_filters, 4, padding=2)\n",
    "        self.conv3 = nn.Conv2d(self.conv2_filters, self.conv3_filters, 4, padding=2)\n",
    "        self.pool = nn.MaxPool2d(self.max_pool, self.max_pool)\n",
    "        self.dropout = nn.Dropout(self.drop_percent)\n",
    "        self.linear1 = nn.Linear(self.conv_output, self.linear1_size)\n",
    "        self.linear2 = nn.Linear(self.linear1_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.dropout(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.dropout(F.relu(self.conv2(x))))\n",
    "        x = self.pool(self.dropout(F.relu(self.conv3(x))))\n",
    "        x = x.view(-1, self.conv_output) \n",
    "        x = self.dropout(F.relu((self.linear1(x))))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class VAE_50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_50, self).__init__()\n",
    "        \n",
    "        hidden_dim = 800\n",
    "        latent_dim = 50\n",
    "        self.fc1 = nn.Linear(65536, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 65536)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        #print(\"z.size() =\", z.size())\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        #print(\"h3.size() =\", h3.size())\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 65536))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    \n",
    "class VAE_100(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_100, self).__init__()\n",
    "        \n",
    "        hidden_dim = 800\n",
    "        latent_dim = 100\n",
    "        self.fc1 = nn.Linear(65536, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 65536)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        #print(\"z.size() =\", z.size())\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        #print(\"h3.size() =\", h3.size())\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 65536))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "class VAE_200(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_200, self).__init__()\n",
    "        \n",
    "        hidden_dim = 800\n",
    "        latent_dim = 200\n",
    "        self.fc1 = nn.Linear(65536, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 65536)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        #print(\"z.size() =\", z.size())\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        #print(\"h3.size() =\", h3.size())\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 65536))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://gist.github.com/stefanonardo/693d96ceb2f531fa05db530f3e21517d\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=True):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False, final_testing=True):\n",
    "    es = EarlyStopping(patience = 15)\n",
    "    stop_now = 0\n",
    "\n",
    "    since = time.time()\n",
    "    classnames = ['Other', 'Saggital_Right', 'Transverse_Right', 'Saggital_Left','Transverse_Left', 'Bladder']\n",
    "    val_acc_history = []\n",
    "    \n",
    "    val_metrics_list = []\n",
    "    train_metrics_list = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    epoch_with_best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 54)\n",
    "\n",
    "        if stop_now:\n",
    "            break\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            running_preds = []\n",
    "            running_labels = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.type(torch.long)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        labels = torch.argmax(labels, 1)\n",
    "                        running_preds += torch.argmax(outputs, 1).tolist()\n",
    "                        running_labels += labels.tolist()\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} loss:\\t{:.4f} | {} acc:\\t{:.4f}\\n'.format(phase, epoch_loss, phase, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                wandb.log({'epoch': epoch, 'train_acc':epoch_acc, 'train_loss':epoch_loss})\n",
    "                \n",
    "                cur_train_metrics = {}\n",
    "                                # compute and log f1, precision, recall for each class\n",
    "                for c in range(6):\n",
    "                    running_labels = np.asarray(running_labels)\n",
    "                    running_preds = np.asarray(running_preds)\n",
    "\n",
    "                    cur_c_labs_bin = np.asarray([0] *len(running_labels))\n",
    "                    cur_c_preds_bin = np.asarray([0] *len(running_labels))\n",
    "\n",
    "                    # Need to binarize\n",
    "                    cur_c_preds_bin[running_preds == c] = 1\n",
    "                    cur_c_labs_bin[running_labels == c] = 1\n",
    "                    f1 = f1_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    precision = precision_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    recall = recall_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    \n",
    "                    cur_train_metrics['train_' + label_unmapping[c] + '_f1'] = f1\n",
    "                    cur_train_metrics['train_' + label_unmapping[c] + '_precision'] = precision\n",
    "                    cur_train_metrics['train_' + label_unmapping[c] + '_recall'] = recall\n",
    "                    \n",
    "                \n",
    "                train_metrics_list.append(cur_train_metrics)\n",
    "                \n",
    "                average_types = ['macro', 'micro', 'weighted']\n",
    "                average_metrics_to_log = ['precision', 'recall', 'f1score', 'support']\n",
    "                average_dict = {'epoch': epoch}\n",
    "                for av in average_types:\n",
    "                    results_tuple = precision_recall_fscore_support(running_labels, running_preds, average=av)\n",
    "                    for m in range(len(average_metrics_to_log)):      \n",
    "                        average_dict[phase + '_'+ average_metrics_to_log[m] +'_average_' + av] = results_tuple[m]\n",
    "                        cur_train_metrics[phase + '_'+ average_metrics_to_log[m] +'_average_' + av] = results_tuple[m]\n",
    "                cur_train_metrics[phase + '_acc_average'] = accuracy_score(running_labels, running_preds)                  \n",
    "                average_dict[phase + '_acc_average'] = accuracy_score(running_labels, running_preds)     \n",
    "                wandb.log(cur_train_metrics)\n",
    "                \n",
    "            if phase == 'test':\n",
    "                wandb.log({'test_loss':epoch_loss, 'test_acc':epoch_acc, 'epoch': epoch})\n",
    "               \n",
    "            \n",
    "                cur_val_metrics = {}\n",
    "                # compute and log f1, precision, recall for each class\n",
    "                for c in range(6):\n",
    "                    running_labels = np.asarray(running_labels)\n",
    "                    running_preds = np.asarray(running_preds)\n",
    "\n",
    "                    cur_c_labs_bin = np.asarray([0] *len(running_labels))\n",
    "                    cur_c_preds_bin = np.asarray([0] *len(running_labels))\n",
    "\n",
    "                    # Need to binarize\n",
    "                    cur_c_preds_bin[running_preds == c] = 1\n",
    "                    cur_c_labs_bin[running_labels == c] = 1\n",
    "                    f1 = f1_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    precision = precision_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    recall = recall_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                    wandb.log({'valid_' + label_unmapping[c] + '_f1': f1})\n",
    "                    wandb.log({'valid_' + label_unmapping[c] + '_precision': precision})\n",
    "                    wandb.log({'valid_' + label_unmapping[c] + '_recall': recall})\n",
    "                \n",
    "                    cur_val_metrics['val_' + label_unmapping[c] + '_f1'] = f1\n",
    "                    cur_val_metrics['val_' + label_unmapping[c] + '_precision'] = precision\n",
    "                    cur_val_metrics['val_' + label_unmapping[c] + '_recall'] = recall\n",
    "                \n",
    "                average_types = ['macro', 'micro', 'weighted']\n",
    "                average_metrics_to_log = ['precision', 'recall', 'f1score']\n",
    "                average_dict = {'epoch': epoch}\n",
    "                for av in average_types:\n",
    "                    results_tuple = precision_recall_fscore_support(running_labels, running_preds, average=av)\n",
    "                    for m in range(len(average_metrics_to_log)):      \n",
    "                        average_dict[phase + '_'+ average_metrics_to_log[m] +'_average_' + av] = results_tuple[m]\n",
    "                        cur_val_metrics[phase + '_'+ average_metrics_to_log[m] +'_average_' + av] = results_tuple[m]\n",
    "                cur_val_metrics[phase + '_acc_average'] = accuracy_score(running_labels, running_preds)                  \n",
    "                average_dict[phase + '_acc_average'] = accuracy_score(running_labels, running_preds)     \n",
    "                print(cur_val_metrics)\n",
    "                wandb.log(cur_val_metrics)\n",
    "                \n",
    "                \n",
    "                val_metrics_list.append(cur_val_metrics)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                print(classification_report(running_labels, running_preds))\n",
    "                train_acc = epoch_acc\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_acc_train = train_acc\n",
    "                epoch_with_best_val_acc = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"model.pt\"))\n",
    "                print(classification_report(running_labels, running_preds))\n",
    "\n",
    "            if phase == 'test':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                if es.step(epoch_loss) and not final_testing:\n",
    "                    stop_now = 1\n",
    "                    print(\"EARLY STOPPING \" + str(epoch))\n",
    "                    break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}\\n'.format(best_acc))\n",
    "    \n",
    "    # Directly save the best results in this fold\n",
    "    wandb.config.best_acc = best_acc\n",
    "    wandb.config.best_epoch = epoch_with_best_val_acc\n",
    "\n",
    "    wandb.config.val_acc_history = val_acc_history\n",
    "    wandb.config.best_epoch = epoch_with_best_val_acc\n",
    "    \n",
    "    wandb.config.update(val_metrics_list[epoch_with_best_val_acc])\n",
    "    wandb.config.update(train_metrics_list[epoch_with_best_val_acc])\n",
    "    \n",
    "    metrics_from_best_epoch = {'best_epoch': epoch_with_best_val_acc, 'last_epoch': epoch}\n",
    "    metrics_from_best_epoch.update( val_metrics_list[epoch_with_best_val_acc] )\n",
    "    metrics_from_best_epoch.update( train_metrics_list[epoch_with_best_val_acc] )\n",
    "    metrics_from_best_epoch.update( {'val_acc': best_acc.data.cpu(), 'train_acc': best_acc_train.data.cpu()} )    \n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, metrics_from_best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdSxc4Dhc-JT"
   },
   "outputs": [],
   "source": [
    "def train5fold(network_configs,criterion_used,  model_ft, lr, wd, amsgrad, i):\n",
    "    fold = ['test']\n",
    "\n",
    "    random_str = str(uuid.uuid4()).split(\"-\")[0]\n",
    "    best_metrics_per_fold = []\n",
    "    model_base = copy.deepcopy(model_ft)\n",
    "    for fold in folds:\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%d-%m-%Y.%H:%M:%S\")\n",
    "        wandb.init(project='hnultra_test', entity=wandb_username, name=local_username + '_fold_' + fold, group=random_str)\n",
    "        partition = all_folds[fold]\n",
    "\n",
    "        model_ft = copy.deepcopy(model_base)\n",
    "        model_ft = model_ft.to(device)\n",
    "        wandb.watch(model_ft)\n",
    "\n",
    "        # Gather the parameters to be optimized/updated in this run. If we are\n",
    "        #  finetuning we will be updating all parameters. However, if we are\n",
    "        #  doing feature extract method, we will only update the parameters\n",
    "        #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "        #  is True.\n",
    "        params_to_update = model_ft.parameters()\n",
    "        #print(\"Params to learn:\")\n",
    "        if feature_extract:\n",
    "            params_to_update = []\n",
    "            for name,param in model_ft.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    params_to_update.append(param)\n",
    "                    print(\"\\t\",name)\n",
    "        else:\n",
    "            for name,param in model_ft.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(\"\\t\",name)\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer_ft = optim.Adam(params_to_update, lr=lr, weight_decay=wd, amsgrad=amsgrad)\n",
    "\n",
    "        # Setup the loss fxn\n",
    "        criterion = criterion_used\n",
    "\n",
    "        shuffle = True\n",
    "        num_workers = 0\n",
    "        params = {'batch_size': batch_size,\n",
    "                  'shuffle': shuffle,\n",
    "                  'num_workers': num_workers}\n",
    "\n",
    "        config_dict = {'i': i, 'batch_size': batch_size, 'shuffle': shuffle, 'num_workers': num_workers, 'fold': fold,\n",
    "                       'lr': lr, 'wd': wd, 'amsgrad': amsgrad, 'model_name': model_name,'criterion': criterion, 'num_classes': num_classes, \n",
    "                       'num_epochs': num_epochs, 'feature_extract': feature_extract, \"pretrain\": pretrain }\n",
    "\n",
    "        wandb.config.update(config_dict)\n",
    "        wandb.config.update(network_configs)\n",
    "        # Tranforms\n",
    "        trans = transforms.Compose([transforms.RandomAffine(degrees=8, translate=(0.1, 0.1), scale=(0.95,1.25))])\n",
    "\n",
    "        # Generators\n",
    "        training_set = Dataset(partition['train_ids'], partition['train_labels'], transformations=trans)\n",
    "        training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "        validation_set = Dataset(partition['test_ids'], partition['test_labels'])\n",
    "        validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "        dataloaders_dict = {'train':training_generator, 'test':validation_generator}\n",
    "\n",
    "        # Train & Evaluate\n",
    "        model_ft, hist, metrics_from_best_epoch = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs, is_inception=(model_name==\"inception\"))\n",
    "        best_metrics_per_fold.append(metrics_from_best_epoch)\n",
    "\n",
    "    # Calculate the performance metrics on the best model in each fold\n",
    "    wandb.init(project='hnultra', entity=wandb_username, name=local_username + '_ALL', group=random_str)\n",
    "    config_dict['fold'] = -1\n",
    "    wandb.config.update(config_dict)\n",
    "    wandb.config.update(network_configs)\n",
    "\n",
    "\n",
    "    metrics_all = {}\n",
    "    for fold in best_metrics_per_fold:\n",
    "        for key in fold:\n",
    "            if key not in metrics_all:\n",
    "                metrics_all[key] = [fold[key]]\n",
    "            else:\n",
    "                metrics_all[key].append(fold[key]) \n",
    "\n",
    "    metrics_to_log = {}\n",
    "    for m in metrics_all:\n",
    "        metric_list = np.asarray(metrics_all[m])\n",
    "\n",
    "        metrics_to_log[m + '_mean'] = metric_list.mean()    \n",
    "        metrics_to_log[m + '_stdev'] = metric_list.std()\n",
    "\n",
    "    wandb.config.update(metrics_to_log)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iikM7_G3c-JR"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels, transformations=None):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transformations = transformations\n",
    "        \n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        img_path = data_dir + ID + '.jpg'\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        \n",
    "        if self.transformations:\n",
    "            image = self.transformations(image)\n",
    "        \n",
    "        image = ToTensor()(image)\n",
    "        \n",
    "        y = torch.FloatTensor([0]*6)        \n",
    "        y[int(self.labels[index])] = 1\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception, viewnet]\n",
    "model_name = \"viewnet\"\n",
    "\n",
    "# Number of classes in the dataset: right_sag, right_trav, left_sag, left_trav, bladder, other\n",
    "num_classes = 6\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 100\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 46\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model; when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "\n",
    "# Flag for whether or not to use pretrained model\n",
    "pretrain = False\n",
    "\n",
    "criterion_used = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_output:  512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denizjafari/hnultra_test\" target=\"_blank\">https://app.wandb.ai/denizjafari/hnultra_test</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denizjafari/hnultra_test/runs/1lf0ou1z\" target=\"_blank\">https://app.wandb.ai/denizjafari/hnultra_test/runs/1lf0ou1z</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.31 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t conv1.weight\n",
      "\t conv1.bias\n",
      "\t conv2.weight\n",
      "\t conv2.bias\n",
      "\t conv3.weight\n",
      "\t conv3.bias\n",
      "\t linear1.weight\n",
      "\t linear1.bias\n",
      "\t linear2.weight\n",
      "\t linear2.bias\n",
      "Epoch 1/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.5708 | train acc:\t0.3827\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.90      0.53      4943\n",
      "           1       0.34      0.07      0.12      2225\n",
      "           2       0.00      0.00      0.00      1539\n",
      "           3       0.31      0.15      0.20      2284\n",
      "           4       0.19      0.00      0.00      1669\n",
      "           5       0.58      0.30      0.39      1298\n",
      "\n",
      "    accuracy                           0.38     13958\n",
      "   macro avg       0.30      0.24      0.21     13958\n",
      "weighted avg       0.32      0.38      0.28     13958\n",
      "\n",
      "test loss:\t1.4995 | test acc:\t0.4617\n",
      "\n",
      "{'val_Other_f1': 0.5904466287290913, 'val_Other_precision': 0.44946180099763716, 'val_Other_recall': 0.8603015075376884, 'val_Saggital_Right_f1': 0.2158119658119658, 'val_Saggital_Right_precision': 0.6917808219178082, 'val_Saggital_Right_recall': 0.12784810126582277, 'val_Transverse_Right_f1': 0.0, 'val_Transverse_Right_precision': 0.0, 'val_Transverse_Right_recall': 0.0, 'val_Saggital_Left_f1': 0.291866028708134, 'val_Saggital_Left_precision': 0.32105263157894737, 'val_Saggital_Left_recall': 0.2675438596491228, 'val_Transverse_Left_f1': 0.003738317757009346, 'val_Transverse_Left_precision': 0.125, 'val_Transverse_Left_recall': 0.0018975332068311196, 'val_Bladder_f1': 0.6825396825396824, 'val_Bladder_precision': 0.6405959031657356, 'val_Bladder_recall': 0.7303609341825902, 'test_precision_average_macro': 0.3713151929433547, 'test_recall_average_macro': 0.33132532264034253, 'test_f1score_average_macro': 0.29740043725764714, 'test_precision_average_micro': 0.46173570019723864, 'test_recall_average_micro': 0.46173570019723864, 'test_f1score_average_micro': 0.46173570019723864, 'test_precision_average_weighted': 0.4000259376117215, 'test_recall_average_weighted': 0.46173570019723864, 'test_f1score_average_weighted': 0.36855283860608334, 'test_acc_average': 0.46173570019723864}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.86      0.59      1990\n",
      "           1       0.69      0.13      0.22       790\n",
      "           2       0.00      0.00      0.00       608\n",
      "           3       0.32      0.27      0.29       684\n",
      "           4       0.12      0.00      0.00       527\n",
      "           5       0.64      0.73      0.68       471\n",
      "\n",
      "    accuracy                           0.46      5070\n",
      "   macro avg       0.37      0.33      0.30      5070\n",
      "weighted avg       0.40      0.46      0.37      5070\n",
      "\n",
      "Epoch 2/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.4017 | train acc:\t0.4519\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.79      0.57      4943\n",
      "           1       0.42      0.28      0.33      2225\n",
      "           2       0.68      0.02      0.04      1539\n",
      "           3       0.37      0.35      0.36      2284\n",
      "           4       0.38      0.06      0.11      1669\n",
      "           5       0.63      0.66      0.65      1298\n",
      "\n",
      "    accuracy                           0.45     13958\n",
      "   macro avg       0.49      0.36      0.34     13958\n",
      "weighted avg       0.47      0.45      0.39     13958\n",
      "\n",
      "test loss:\t1.4548 | test acc:\t0.4783\n",
      "\n",
      "{'val_Other_f1': 0.5925460636515913, 'val_Other_precision': 0.5078966259870783, 'val_Other_recall': 0.7110552763819096, 'val_Saggital_Right_f1': 0.4245810055865921, 'val_Saggital_Right_precision': 0.4165651644336175, 'val_Saggital_Right_recall': 0.43291139240506327, 'val_Transverse_Right_f1': 0.006546644844517185, 'val_Transverse_Right_precision': 0.6666666666666666, 'val_Transverse_Right_recall': 0.003289473684210526, 'val_Saggital_Left_f1': 0.3293172690763052, 'val_Saggital_Left_precision': 0.3037037037037037, 'val_Saggital_Left_recall': 0.35964912280701755, 'val_Transverse_Left_f1': 0.08376963350785341, 'val_Transverse_Left_precision': 0.5217391304347826, 'val_Transverse_Left_recall': 0.04554079696394687, 'val_Bladder_f1': 0.7367441860465116, 'val_Bladder_precision': 0.6556291390728477, 'val_Bladder_recall': 0.8407643312101911, 'test_precision_average_macro': 0.5120334050497828, 'test_recall_average_macro': 0.39886839890872317, 'test_f1score_average_macro': 0.36225080045222846, 'test_precision_average_micro': 0.47830374753451677, 'test_recall_average_micro': 0.47830374753451677, 'test_f1score_average_micro': 0.47830374753451677, 'test_precision_average_weighted': 0.500320567756598, 'test_recall_average_weighted': 0.47830374753451677, 'test_f1score_average_weighted': 0.42109904175153434, 'test_acc_average': 0.47830374753451677}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.71      0.59      1990\n",
      "           1       0.42      0.43      0.42       790\n",
      "           2       0.67      0.00      0.01       608\n",
      "           3       0.30      0.36      0.33       684\n",
      "           4       0.52      0.05      0.08       527\n",
      "           5       0.66      0.84      0.74       471\n",
      "\n",
      "    accuracy                           0.48      5070\n",
      "   macro avg       0.51      0.40      0.36      5070\n",
      "weighted avg       0.50      0.48      0.42      5070\n",
      "\n",
      "Epoch 3/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.3393 | train acc:\t0.4771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58      4943\n",
      "           1       0.45      0.37      0.41      2225\n",
      "           2       0.50      0.07      0.13      1539\n",
      "           3       0.41      0.39      0.40      2284\n",
      "           4       0.38      0.11      0.17      1669\n",
      "           5       0.68      0.68      0.68      1298\n",
      "\n",
      "    accuracy                           0.48     13958\n",
      "   macro avg       0.48      0.40      0.39     13958\n",
      "weighted avg       0.47      0.48      0.43     13958\n",
      "\n",
      "test loss:\t1.4438 | test acc:\t0.5059\n",
      "\n",
      "{'val_Other_f1': 0.6090589270008794, 'val_Other_precision': 0.5414386239249414, 'val_Other_recall': 0.6959798994974874, 'val_Saggital_Right_f1': 0.4013840830449827, 'val_Saggital_Right_precision': 0.6338797814207651, 'val_Saggital_Right_recall': 0.2936708860759494, 'val_Transverse_Right_f1': 0.17997097242380258, 'val_Transverse_Right_precision': 0.7654320987654321, 'val_Transverse_Right_recall': 0.10197368421052631, 'val_Saggital_Left_f1': 0.39355581127733025, 'val_Saggital_Left_precision': 0.32447817836812143, 'val_Saggital_Left_recall': 0.5, 'val_Transverse_Left_f1': 0.31086956521739134, 'val_Transverse_Left_precision': 0.3638676844783715, 'val_Transverse_Left_recall': 0.2713472485768501, 'val_Bladder_f1': 0.7364554637281909, 'val_Bladder_precision': 0.6488673139158576, 'val_Bladder_recall': 0.851380042462845, 'test_precision_average_macro': 0.5463272801455816, 'test_recall_average_macro': 0.45239196013727634, 'test_f1score_average_macro': 0.43854913711542953, 'test_precision_average_micro': 0.5059171597633136, 'test_recall_average_micro': 0.5059171597633136, 'test_f1score_average_micro': 0.5059171597633136, 'test_precision_average_weighted': 0.5449563024774529, 'test_recall_average_weighted': 0.5059171597633136, 'test_f1score_average_weighted': 0.4770086786528985, 'test_acc_average': 0.5059171597633136}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61      1990\n",
      "           1       0.63      0.29      0.40       790\n",
      "           2       0.77      0.10      0.18       608\n",
      "           3       0.32      0.50      0.39       684\n",
      "           4       0.36      0.27      0.31       527\n",
      "           5       0.65      0.85      0.74       471\n",
      "\n",
      "    accuracy                           0.51      5070\n",
      "   macro avg       0.55      0.45      0.44      5070\n",
      "weighted avg       0.54      0.51      0.48      5070\n",
      "\n",
      "Epoch 4/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.2946 | train acc:\t0.4968\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.75      0.59      4943\n",
      "           1       0.50      0.40      0.44      2225\n",
      "           2       0.47      0.13      0.20      1539\n",
      "           3       0.43      0.41      0.42      2284\n",
      "           4       0.44      0.19      0.27      1669\n",
      "           5       0.69      0.68      0.69      1298\n",
      "\n",
      "    accuracy                           0.50     13958\n",
      "   macro avg       0.50      0.43      0.43     13958\n",
      "weighted avg       0.49      0.50      0.47     13958\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:\t1.4031 | test acc:\t0.5101\n",
      "\n",
      "{'val_Other_f1': 0.6018581463856787, 'val_Other_precision': 0.5480808914568717, 'val_Other_recall': 0.6673366834170854, 'val_Saggital_Right_f1': 0.41059602649006627, 'val_Saggital_Right_precision': 0.5933014354066986, 'val_Saggital_Right_recall': 0.3139240506329114, 'val_Transverse_Right_f1': 0.3111668757841907, 'val_Transverse_Right_precision': 0.656084656084656, 'val_Transverse_Right_recall': 0.20394736842105263, 'val_Saggital_Left_f1': 0.4097610574478902, 'val_Saggital_Left_precision': 0.3141075604053001, 'val_Saggital_Left_recall': 0.5891812865497076, 'val_Transverse_Left_f1': 0.25771812080536916, 'val_Transverse_Left_precision': 0.44036697247706424, 'val_Transverse_Left_recall': 0.18216318785578747, 'val_Bladder_f1': 0.7663366336633664, 'val_Bladder_precision': 0.7179962894248608, 'val_Bladder_recall': 0.821656050955414, 'test_precision_average_macro': 0.5449896342092418, 'test_recall_average_macro': 0.46303477130532644, 'test_f1score_average_macro': 0.4595728100960936, 'test_precision_average_micro': 0.5100591715976331, 'test_recall_average_micro': 0.5100591715976331, 'test_f1score_average_micro': 0.5100591715976331, 'test_precision_average_weighted': 0.5411021295861311, 'test_recall_average_weighted': 0.5100591715976331, 'test_f1score_average_weighted': 0.49078828404845615, 'test_acc_average': 0.5100591715976331}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60      1990\n",
      "           1       0.59      0.31      0.41       790\n",
      "           2       0.66      0.20      0.31       608\n",
      "           3       0.31      0.59      0.41       684\n",
      "           4       0.44      0.18      0.26       527\n",
      "           5       0.72      0.82      0.77       471\n",
      "\n",
      "    accuracy                           0.51      5070\n",
      "   macro avg       0.54      0.46      0.46      5070\n",
      "weighted avg       0.54      0.51      0.49      5070\n",
      "\n",
      "Epoch 5/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.2739 | train acc:\t0.5001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60      4943\n",
      "           1       0.50      0.39      0.44      2225\n",
      "           2       0.46      0.16      0.23      1539\n",
      "           3       0.42      0.41      0.41      2284\n",
      "           4       0.41      0.20      0.27      1669\n",
      "           5       0.72      0.71      0.71      1298\n",
      "\n",
      "    accuracy                           0.50     13958\n",
      "   macro avg       0.50      0.44      0.44     13958\n",
      "weighted avg       0.49      0.50      0.47     13958\n",
      "\n",
      "test loss:\t1.3726 | test acc:\t0.5258\n",
      "\n",
      "{'val_Other_f1': 0.6188663282571912, 'val_Other_precision': 0.5343316289262235, 'val_Other_recall': 0.7351758793969849, 'val_Saggital_Right_f1': 0.42892358258011504, 'val_Saggital_Right_precision': 0.6112412177985949, 'val_Saggital_Right_recall': 0.330379746835443, 'val_Transverse_Right_f1': 0.3870967741935484, 'val_Transverse_Right_precision': 0.5, 'val_Transverse_Right_recall': 0.3157894736842105, 'val_Saggital_Left_f1': 0.3432835820895523, 'val_Saggital_Left_precision': 0.39655172413793105, 'val_Saggital_Left_recall': 0.3026315789473684, 'val_Transverse_Left_f1': 0.35203094777562866, 'val_Transverse_Left_precision': 0.358974358974359, 'val_Transverse_Left_recall': 0.34535104364326374, 'val_Bladder_f1': 0.7497403946002077, 'val_Bladder_precision': 0.733739837398374, 'val_Bladder_recall': 0.7664543524416136, 'test_precision_average_macro': 0.5224731278725804, 'test_recall_average_macro': 0.4659636791581474, 'test_f1score_average_macro': 0.4799902682493739, 'test_precision_average_micro': 0.5258382642998027, 'test_recall_average_micro': 0.5258382642998027, 'test_f1score_average_micro': 0.5258382642998027, 'test_precision_average_weighted': 0.5239078567117438, 'test_recall_average_weighted': 0.5258382642998027, 'test_f1score_average_weighted': 0.5087184354365852, 'test_acc_average': 0.5258382642998027}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.74      0.62      1990\n",
      "           1       0.61      0.33      0.43       790\n",
      "           2       0.50      0.32      0.39       608\n",
      "           3       0.40      0.30      0.34       684\n",
      "           4       0.36      0.35      0.35       527\n",
      "           5       0.73      0.77      0.75       471\n",
      "\n",
      "    accuracy                           0.53      5070\n",
      "   macro avg       0.52      0.47      0.48      5070\n",
      "weighted avg       0.52      0.53      0.51      5070\n",
      "\n",
      "Epoch 6/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.2568 | train acc:\t0.5105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.60      4943\n",
      "           1       0.52      0.40      0.45      2225\n",
      "           2       0.48      0.19      0.27      1539\n",
      "           3       0.45      0.43      0.44      2284\n",
      "           4       0.44      0.25      0.32      1669\n",
      "           5       0.72      0.71      0.71      1298\n",
      "\n",
      "    accuracy                           0.51     13958\n",
      "   macro avg       0.52      0.45      0.46     13958\n",
      "weighted avg       0.51      0.51      0.49     13958\n",
      "\n",
      "test loss:\t1.3812 | test acc:\t0.5128\n",
      "\n",
      "{'val_Other_f1': 0.5737868934467234, 'val_Other_precision': 0.5712151394422311, 'val_Other_recall': 0.5763819095477387, 'val_Saggital_Right_f1': 0.45028759244042726, 'val_Saggital_Right_precision': 0.6416861826697893, 'val_Saggital_Right_recall': 0.3468354430379747, 'val_Transverse_Right_f1': 0.40545808966861596, 'val_Transverse_Right_precision': 0.49760765550239233, 'val_Transverse_Right_recall': 0.34210526315789475, 'val_Saggital_Left_f1': 0.41592312971859985, 'val_Saggital_Left_precision': 0.39197930142302717, 'val_Saggital_Left_recall': 0.44298245614035087, 'val_Transverse_Left_f1': 0.3827893175074184, 'val_Transverse_Left_precision': 0.31425091352009743, 'val_Transverse_Left_recall': 0.48956356736242884, 'val_Bladder_f1': 0.7495429616087752, 'val_Bladder_precision': 0.6581059390048154, 'val_Bladder_recall': 0.8704883227176221, 'test_precision_average_macro': 0.5124741885937255, 'test_recall_average_macro': 0.5113928269940017, 'test_f1score_average_macro': 0.49629799739842667, 'test_precision_average_micro': 0.5128205128205128, 'test_recall_average_micro': 0.5128205128205128, 'test_f1score_average_micro': 0.5128205128205128, 'test_precision_average_weighted': 0.5305498298253132, 'test_recall_average_weighted': 0.5128205128205128, 'test_f1score_average_weighted': 0.5095340750447931, 'test_acc_average': 0.5128205128205128}\n",
      "Epoch 7/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.2293 | train acc:\t0.5208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.73      0.60      4943\n",
      "           1       0.54      0.40      0.46      2225\n",
      "           2       0.50      0.24      0.32      1539\n",
      "           3       0.45      0.45      0.45      2284\n",
      "           4       0.44      0.28      0.34      1669\n",
      "           5       0.73      0.71      0.72      1298\n",
      "\n",
      "    accuracy                           0.52     13958\n",
      "   macro avg       0.53      0.47      0.48     13958\n",
      "weighted avg       0.52      0.52      0.50     13958\n",
      "\n",
      "test loss:\t1.3655 | test acc:\t0.5351\n",
      "\n",
      "{'val_Other_f1': 0.6193056391731887, 'val_Other_precision': 0.5155362512529235, 'val_Other_recall': 0.7753768844221105, 'val_Saggital_Right_f1': 0.4087193460490463, 'val_Saggital_Right_precision': 0.7234726688102894, 'val_Saggital_Right_recall': 0.2848101265822785, 'val_Transverse_Right_f1': 0.38675213675213677, 'val_Transverse_Right_precision': 0.551829268292683, 'val_Transverse_Right_recall': 0.29769736842105265, 'val_Saggital_Left_f1': 0.345374449339207, 'val_Saggital_Left_precision': 0.43458980044345896, 'val_Saggital_Left_recall': 0.28654970760233917, 'val_Transverse_Left_f1': 0.3892215568862275, 'val_Transverse_Left_precision': 0.4105263157894737, 'val_Transverse_Left_recall': 0.3700189753320683, 'val_Bladder_f1': 0.7589013224821973, 'val_Bladder_precision': 0.728515625, 'val_Bladder_recall': 0.7919320594479831, 'test_precision_average_macro': 0.5607449882648047, 'test_recall_average_macro': 0.4677308536346387, 'test_f1score_average_macro': 0.48471240844700053, 'test_precision_average_micro': 0.5351084812623275, 'test_recall_average_micro': 0.5351084812623275, 'test_f1score_average_micro': 0.5351084812623275, 'test_precision_average_weighted': 0.5502387366419677, 'test_recall_average_weighted': 0.5351084812623275, 'test_f1score_average_weighted': 0.5107002388944508, 'test_acc_average': 0.5351084812623275}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.78      0.62      1990\n",
      "           1       0.72      0.28      0.41       790\n",
      "           2       0.55      0.30      0.39       608\n",
      "           3       0.43      0.29      0.35       684\n",
      "           4       0.41      0.37      0.39       527\n",
      "           5       0.73      0.79      0.76       471\n",
      "\n",
      "    accuracy                           0.54      5070\n",
      "   macro avg       0.56      0.47      0.48      5070\n",
      "weighted avg       0.55      0.54      0.51      5070\n",
      "\n",
      "Epoch 8/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t1.2019 | train acc:\t0.5363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.74      0.62      4943\n",
      "           1       0.57      0.42      0.48      2225\n",
      "           2       0.50      0.24      0.33      1539\n",
      "           3       0.47      0.47      0.47      2284\n",
      "           4       0.47      0.29      0.36      1669\n",
      "           5       0.75      0.73      0.74      1298\n",
      "\n",
      "    accuracy                           0.54     13958\n",
      "   macro avg       0.55      0.48      0.50     13958\n",
      "weighted avg       0.53      0.54      0.52     13958\n",
      "\n",
      "test loss:\t1.3245 | test acc:\t0.5464\n",
      "\n",
      "{'val_Other_f1': 0.6297996661101837, 'val_Other_precision': 0.538543897216274, 'val_Other_recall': 0.7582914572864322, 'val_Saggital_Right_f1': 0.4751381215469613, 'val_Saggital_Right_precision': 0.6310272536687631, 'val_Saggital_Right_recall': 0.3810126582278481, 'val_Transverse_Right_f1': 0.282258064516129, 'val_Transverse_Right_precision': 0.7720588235294118, 'val_Transverse_Right_recall': 0.17269736842105263, 'val_Saggital_Left_f1': 0.4006259780907668, 'val_Saggital_Left_precision': 0.43097643097643096, 'val_Saggital_Left_recall': 0.3742690058479532, 'val_Transverse_Left_f1': 0.3892215568862275, 'val_Transverse_Left_precision': 0.4105263157894737, 'val_Transverse_Left_recall': 0.3700189753320683, 'val_Bladder_f1': 0.7644276253547777, 'val_Bladder_precision': 0.689419795221843, 'val_Bladder_recall': 0.8577494692144374, 'test_precision_average_macro': 0.5787587527336994, 'test_recall_average_macro': 0.485673155721632, 'test_f1score_average_macro': 0.49024516875084095, 'test_precision_average_micro': 0.5463510848126233, 'test_recall_average_micro': 0.5463510848126233, 'test_f1score_average_micro': 0.5463510848126233, 'test_precision_average_weighted': 0.5671553493733748, 'test_recall_average_weighted': 0.5463510848126233, 'test_f1score_average_weighted': 0.5206048709748319, 'test_acc_average': 0.5463510848126233}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.76      0.63      1990\n",
      "           1       0.63      0.38      0.48       790\n",
      "           2       0.77      0.17      0.28       608\n",
      "           3       0.43      0.37      0.40       684\n",
      "           4       0.41      0.37      0.39       527\n",
      "           5       0.69      0.86      0.76       471\n",
      "\n",
      "    accuracy                           0.55      5070\n",
      "   macro avg       0.58      0.49      0.49      5070\n",
      "weighted avg       0.57      0.55      0.52      5070\n",
      "\n",
      "Epoch 9/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1844 | train acc:\t0.5454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.74      0.62      4943\n",
      "           1       0.59      0.44      0.50      2225\n",
      "           2       0.52      0.26      0.35      1539\n",
      "           3       0.49      0.47      0.48      2284\n",
      "           4       0.47      0.33      0.39      1669\n",
      "           5       0.74      0.72      0.73      1298\n",
      "\n",
      "    accuracy                           0.55     13958\n",
      "   macro avg       0.56      0.49      0.51     13958\n",
      "weighted avg       0.55      0.55      0.53     13958\n",
      "\n",
      "test loss:\t1.3544 | test acc:\t0.5179\n",
      "\n",
      "{'val_Other_f1': 0.5671957671957673, 'val_Other_precision': 0.5988826815642458, 'val_Other_recall': 0.5386934673366834, 'val_Saggital_Right_f1': 0.4187662901824501, 'val_Saggital_Right_precision': 0.667590027700831, 'val_Saggital_Right_recall': 0.3050632911392405, 'val_Transverse_Right_f1': 0.45919282511210757, 'val_Transverse_Right_precision': 0.504930966469428, 'val_Transverse_Right_recall': 0.42105263157894735, 'val_Saggital_Left_f1': 0.4205962059620596, 'val_Saggital_Left_precision': 0.3341946597760551, 'val_Saggital_Left_recall': 0.5672514619883041, 'val_Transverse_Left_f1': 0.43435177539223774, 'val_Transverse_Left_precision': 0.3845029239766082, 'val_Transverse_Left_recall': 0.4990512333965844, 'val_Bladder_f1': 0.7822736030828517, 'val_Bladder_precision': 0.7160493827160493, 'val_Bladder_recall': 0.861995753715499, 'test_precision_average_macro': 0.5343584403672029, 'test_recall_average_macro': 0.5321846398592097, 'test_f1score_average_macro': 0.513729411154579, 'test_precision_average_micro': 0.517948717948718, 'test_recall_average_micro': 0.517948717948718, 'test_f1score_average_micro': 0.517948717948718, 'test_precision_average_weighted': 0.5512134385190673, 'test_recall_average_weighted': 0.517948717948718, 'test_f1score_average_weighted': 0.5175101067443106, 'test_acc_average': 0.517948717948718}\n",
      "Epoch 10/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1719 | train acc:\t0.5406\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.72      0.61      4943\n",
      "           1       0.58      0.43      0.50      2225\n",
      "           2       0.52      0.28      0.37      1539\n",
      "           3       0.47      0.46      0.46      2284\n",
      "           4       0.46      0.34      0.39      1669\n",
      "           5       0.76      0.74      0.75      1298\n",
      "\n",
      "    accuracy                           0.54     13958\n",
      "   macro avg       0.55      0.50      0.51     13958\n",
      "weighted avg       0.54      0.54      0.53     13958\n",
      "\n",
      "test loss:\t1.2801 | test acc:\t0.5546\n",
      "\n",
      "{'val_Other_f1': 0.6385015608740895, 'val_Other_precision': 0.5449378330373001, 'val_Other_recall': 0.770854271356784, 'val_Saggital_Right_f1': 0.4660194174757281, 'val_Saggital_Right_precision': 0.6457399103139013, 'val_Saggital_Right_recall': 0.36455696202531646, 'val_Transverse_Right_f1': 0.3455233291298865, 'val_Transverse_Right_precision': 0.7405405405405405, 'val_Transverse_Right_recall': 0.22532894736842105, 'val_Saggital_Left_f1': 0.4128571428571428, 'val_Saggital_Left_precision': 0.4036312849162011, 'val_Saggital_Left_recall': 0.42251461988304095, 'val_Transverse_Left_f1': 0.3632183908045977, 'val_Transverse_Left_precision': 0.4606413994169096, 'val_Transverse_Left_recall': 0.2998102466793169, 'val_Bladder_f1': 0.7837837837837838, 'val_Bladder_precision': 0.7185840707964601, 'val_Bladder_recall': 0.861995753715499, 'test_precision_average_macro': 0.5856791731702188, 'test_recall_average_macro': 0.49084346683806307, 'test_f1score_average_macro': 0.5016506041542047, 'test_precision_average_micro': 0.5546351084812623, 'test_recall_average_micro': 0.5546351084812623, 'test_f1score_average_micro': 0.5546351084812623, 'test_precision_average_weighted': 0.5724071753967226, 'test_recall_average_weighted': 0.5546351084812623, 'test_f1score_average_weighted': 0.5309317889322891, 'test_acc_average': 0.5546351084812623}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.77      0.64      1990\n",
      "           1       0.65      0.36      0.47       790\n",
      "           2       0.74      0.23      0.35       608\n",
      "           3       0.40      0.42      0.41       684\n",
      "           4       0.46      0.30      0.36       527\n",
      "           5       0.72      0.86      0.78       471\n",
      "\n",
      "    accuracy                           0.55      5070\n",
      "   macro avg       0.59      0.49      0.50      5070\n",
      "weighted avg       0.57      0.55      0.53      5070\n",
      "\n",
      "Epoch 11/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1578 | train acc:\t0.5546\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.62      4943\n",
      "           1       0.60      0.44      0.51      2225\n",
      "           2       0.54      0.30      0.39      1539\n",
      "           3       0.49      0.50      0.49      2284\n",
      "           4       0.47      0.33      0.39      1669\n",
      "           5       0.76      0.74      0.75      1298\n",
      "\n",
      "    accuracy                           0.55     13958\n",
      "   macro avg       0.57      0.51      0.53     13958\n",
      "weighted avg       0.56      0.55      0.54     13958\n",
      "\n",
      "test loss:\t1.2947 | test acc:\t0.5590\n",
      "\n",
      "{'val_Other_f1': 0.6318161333934205, 'val_Other_precision': 0.5727124183006536, 'val_Other_recall': 0.7045226130653266, 'val_Saggital_Right_f1': 0.42702702702702705, 'val_Saggital_Right_precision': 0.740625, 'val_Saggital_Right_recall': 0.3, 'val_Transverse_Right_f1': 0.44941427050053245, 'val_Transverse_Right_precision': 0.6374622356495468, 'val_Transverse_Right_recall': 0.3470394736842105, 'val_Saggital_Left_f1': 0.4438775510204082, 'val_Saggital_Left_precision': 0.3936651583710407, 'val_Saggital_Left_recall': 0.5087719298245614, 'val_Transverse_Left_f1': 0.4370229007633587, 'val_Transverse_Left_precision': 0.43953934740882916, 'val_Transverse_Left_recall': 0.43453510436432635, 'val_Bladder_f1': 0.7849566055930569, 'val_Bladder_precision': 0.7190812720848057, 'val_Bladder_recall': 0.8641188959660298, 'test_precision_average_macro': 0.5838475719691459, 'test_recall_average_macro': 0.5264980028174091, 'test_f1score_average_macro': 0.5290190813829673, 'test_precision_average_micro': 0.558974358974359, 'test_recall_average_micro': 0.558974358974359, 'test_f1score_average_micro': 0.558974358974359, 'test_precision_average_weighted': 0.5822406282555056, 'test_recall_average_weighted': 0.558974358974359, 'test_f1score_average_weighted': 0.5466562540637397, 'test_acc_average': 0.558974358974359}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.70      0.63      1990\n",
      "           1       0.74      0.30      0.43       790\n",
      "           2       0.64      0.35      0.45       608\n",
      "           3       0.39      0.51      0.44       684\n",
      "           4       0.44      0.43      0.44       527\n",
      "           5       0.72      0.86      0.78       471\n",
      "\n",
      "    accuracy                           0.56      5070\n",
      "   macro avg       0.58      0.53      0.53      5070\n",
      "weighted avg       0.58      0.56      0.55      5070\n",
      "\n",
      "Epoch 12/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t1.1265 | train acc:\t0.5671\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63      4943\n",
      "           1       0.61      0.46      0.52      2225\n",
      "           2       0.57      0.32      0.41      1539\n",
      "           3       0.51      0.50      0.51      2284\n",
      "           4       0.51      0.37      0.43      1669\n",
      "           5       0.77      0.76      0.76      1298\n",
      "\n",
      "    accuracy                           0.57     13958\n",
      "   macro avg       0.59      0.52      0.54     13958\n",
      "weighted avg       0.57      0.57      0.56     13958\n",
      "\n",
      "test loss:\t1.2492 | test acc:\t0.5657\n",
      "\n",
      "{'val_Other_f1': 0.6224535989135356, 'val_Other_precision': 0.5663097199341022, 'val_Other_recall': 0.6909547738693468, 'val_Saggital_Right_f1': 0.5146757679180887, 'val_Saggital_Right_precision': 0.5585185185185185, 'val_Saggital_Right_recall': 0.4772151898734177, 'val_Transverse_Right_f1': 0.4917715392061956, 'val_Transverse_Right_precision': 0.5976470588235294, 'val_Transverse_Right_recall': 0.41776315789473684, 'val_Saggital_Left_f1': 0.40825688073394495, 'val_Saggital_Left_precision': 0.42788461538461536, 'val_Saggital_Left_recall': 0.39035087719298245, 'val_Transverse_Left_f1': 0.41666666666666663, 'val_Transverse_Left_precision': 0.5341246290801187, 'val_Transverse_Left_recall': 0.3415559772296015, 'val_Bladder_f1': 0.7889733840304182, 'val_Bladder_precision': 0.7142857142857143, 'val_Bladder_recall': 0.881104033970276, 'test_precision_average_macro': 0.5664617093377665, 'test_recall_average_macro': 0.5331573350050602, 'test_f1score_average_macro': 0.5404663062448082, 'test_precision_average_micro': 0.565680473372781, 'test_recall_average_micro': 0.565680473372781, 'test_f1score_average_micro': 0.565680473372781, 'test_precision_average_weighted': 0.5605800220789092, 'test_recall_average_weighted': 0.565680473372781, 'test_f1score_average_weighted': 0.5551698457523218, 'test_acc_average': 0.565680473372781}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.62      1990\n",
      "           1       0.56      0.48      0.51       790\n",
      "           2       0.60      0.42      0.49       608\n",
      "           3       0.43      0.39      0.41       684\n",
      "           4       0.53      0.34      0.42       527\n",
      "           5       0.71      0.88      0.79       471\n",
      "\n",
      "    accuracy                           0.57      5070\n",
      "   macro avg       0.57      0.53      0.54      5070\n",
      "weighted avg       0.56      0.57      0.56      5070\n",
      "\n",
      "Epoch 13/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1183 | train acc:\t0.5672\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63      4943\n",
      "           1       0.62      0.46      0.53      2225\n",
      "           2       0.57      0.33      0.42      1539\n",
      "           3       0.51      0.50      0.50      2284\n",
      "           4       0.49      0.36      0.41      1669\n",
      "           5       0.78      0.75      0.76      1298\n",
      "\n",
      "    accuracy                           0.57     13958\n",
      "   macro avg       0.58      0.52      0.54     13958\n",
      "weighted avg       0.57      0.57      0.56     13958\n",
      "\n",
      "test loss:\t1.2669 | test acc:\t0.5550\n",
      "\n",
      "{'val_Other_f1': 0.6373528758605375, 'val_Other_precision': 0.5710306406685237, 'val_Other_recall': 0.7211055276381909, 'val_Saggital_Right_f1': 0.4283216783216782, 'val_Saggital_Right_precision': 0.692090395480226, 'val_Saggital_Right_recall': 0.310126582278481, 'val_Transverse_Right_f1': 0.3966745843230404, 'val_Transverse_Right_precision': 0.7136752136752137, 'val_Transverse_Right_recall': 0.2746710526315789, 'val_Saggital_Left_f1': 0.42765502494654306, 'val_Saggital_Left_precision': 0.4172461752433936, 'val_Saggital_Left_recall': 0.43859649122807015, 'val_Transverse_Left_f1': 0.4280821917808219, 'val_Transverse_Left_precision': 0.39001560062402496, 'val_Transverse_Left_recall': 0.47438330170777987, 'val_Bladder_f1': 0.7722222222222223, 'val_Bladder_precision': 0.6847290640394089, 'val_Bladder_recall': 0.8853503184713376, 'test_precision_average_macro': 0.5781311816217986, 'test_recall_average_macro': 0.5173722123259065, 'test_f1score_average_macro': 0.5150514295758072, 'test_precision_average_micro': 0.5550295857988166, 'test_recall_average_micro': 0.5550295857988166, 'test_f1score_average_micro': 0.5550295857988166, 'test_precision_average_weighted': 0.5779997853712375, 'test_recall_average_weighted': 0.5550295857988166, 'test_f1score_average_weighted': 0.5384056242413411, 'test_acc_average': 0.5550295857988166}\n",
      "Epoch 14/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1053 | train acc:\t0.5777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.74      0.64      4943\n",
      "           1       0.64      0.47      0.54      2225\n",
      "           2       0.57      0.34      0.43      1539\n",
      "           3       0.52      0.52      0.52      2284\n",
      "           4       0.51      0.40      0.45      1669\n",
      "           5       0.77      0.76      0.76      1298\n",
      "\n",
      "    accuracy                           0.58     13958\n",
      "   macro avg       0.59      0.54      0.56     13958\n",
      "weighted avg       0.58      0.58      0.57     13958\n",
      "\n",
      "test loss:\t1.2519 | test acc:\t0.5517\n",
      "\n",
      "{'val_Other_f1': 0.6106086531410413, 'val_Other_precision': 0.5944788196097096, 'val_Other_recall': 0.6276381909547739, 'val_Saggital_Right_f1': 0.492176386913229, 'val_Saggital_Right_precision': 0.5616883116883117, 'val_Saggital_Right_recall': 0.4379746835443038, 'val_Transverse_Right_f1': 0.46794871794871795, 'val_Transverse_Right_precision': 0.6676829268292683, 'val_Transverse_Right_recall': 0.36019736842105265, 'val_Saggital_Left_f1': 0.4256055363321799, 'val_Saggital_Left_precision': 0.3514285714285714, 'val_Saggital_Left_recall': 0.5394736842105263, 'val_Transverse_Left_f1': 0.4331210191082803, 'val_Transverse_Left_precision': 0.491566265060241, 'val_Transverse_Left_recall': 0.3870967741935484, 'val_Bladder_f1': 0.7953443258971873, 'val_Bladder_precision': 0.7321428571428571, 'val_Bladder_recall': 0.8704883227176221, 'test_precision_average_macro': 0.5664979586264932, 'test_recall_average_macro': 0.5371448373403046, 'test_f1score_average_macro': 0.5374674398901059, 'test_precision_average_micro': 0.5516765285996055, 'test_recall_average_micro': 0.5516765285996055, 'test_f1score_average_micro': 0.5516765285996055, 'test_precision_average_weighted': 0.5674496424117277, 'test_recall_average_weighted': 0.5516765285996055, 'test_f1score_average_weighted': 0.5488006957285589, 'test_acc_average': 0.5516765285996055}\n",
      "Epoch 15/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0921 | train acc:\t0.5776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.75      0.64      4943\n",
      "           1       0.62      0.47      0.54      2225\n",
      "           2       0.59      0.34      0.43      1539\n",
      "           3       0.51      0.51      0.51      2284\n",
      "           4       0.51      0.38      0.44      1669\n",
      "           5       0.77      0.76      0.76      1298\n",
      "\n",
      "    accuracy                           0.58     13958\n",
      "   macro avg       0.59      0.54      0.55     13958\n",
      "weighted avg       0.58      0.58      0.57     13958\n",
      "\n",
      "test loss:\t1.2353 | test acc:\t0.5659\n",
      "\n",
      "{'val_Other_f1': 0.6240220892774966, 'val_Other_precision': 0.5755517826825127, 'val_Other_recall': 0.6814070351758794, 'val_Saggital_Right_f1': 0.5109170305676857, 'val_Saggital_Right_precision': 0.601027397260274, 'val_Saggital_Right_recall': 0.4443037974683544, 'val_Transverse_Right_f1': 0.4989979959919839, 'val_Transverse_Right_precision': 0.6384615384615384, 'val_Transverse_Right_recall': 0.4095394736842105, 'val_Saggital_Left_f1': 0.4117236566643405, 'val_Saggital_Left_precision': 0.3938584779706275, 'val_Saggital_Left_recall': 0.43128654970760233, 'val_Transverse_Left_f1': 0.4481409001956947, 'val_Transverse_Left_precision': 0.4626262626262626, 'val_Transverse_Left_recall': 0.43453510436432635, 'val_Bladder_f1': 0.8045501551189246, 'val_Bladder_precision': 0.7842741935483871, 'val_Bladder_recall': 0.8259023354564756, 'test_precision_average_macro': 0.575966608758267, 'test_recall_average_macro': 0.5378290493094747, 'test_f1score_average_macro': 0.5497253046360211, 'test_precision_average_micro': 0.5658777120315582, 'test_recall_average_micro': 0.5658777120315582, 'test_f1score_average_micro': 0.5658777120315582, 'test_precision_average_weighted': 0.5702052645474698, 'test_recall_average_weighted': 0.5658777120315582, 'test_f1score_average_weighted': 0.561252771596917, 'test_acc_average': 0.5658777120315582}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62      1990\n",
      "           1       0.60      0.44      0.51       790\n",
      "           2       0.64      0.41      0.50       608\n",
      "           3       0.39      0.43      0.41       684\n",
      "           4       0.46      0.43      0.45       527\n",
      "           5       0.78      0.83      0.80       471\n",
      "\n",
      "    accuracy                           0.57      5070\n",
      "   macro avg       0.58      0.54      0.55      5070\n",
      "weighted avg       0.57      0.57      0.56      5070\n",
      "\n",
      "Epoch 16/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t1.0758 | train acc:\t0.5836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.74      0.64      4943\n",
      "           1       0.64      0.48      0.55      2225\n",
      "           2       0.58      0.37      0.45      1539\n",
      "           3       0.52      0.51      0.52      2284\n",
      "           4       0.52      0.41      0.46      1669\n",
      "           5       0.77      0.77      0.77      1298\n",
      "\n",
      "    accuracy                           0.58     13958\n",
      "   macro avg       0.60      0.55      0.57     13958\n",
      "weighted avg       0.59      0.58      0.58     13958\n",
      "\n",
      "test loss:\t1.2039 | test acc:\t0.5817\n",
      "\n",
      "{'val_Other_f1': 0.6459652706843719, 'val_Other_precision': 0.5442340791738383, 'val_Other_recall': 0.7944723618090452, 'val_Saggital_Right_f1': 0.5027667984189722, 'val_Saggital_Right_precision': 0.6694736842105263, 'val_Saggital_Right_recall': 0.40253164556962023, 'val_Transverse_Right_f1': 0.4776444929116685, 'val_Transverse_Right_precision': 0.7087378640776699, 'val_Transverse_Right_recall': 0.36019736842105265, 'val_Saggital_Left_f1': 0.4355628058727569, 'val_Saggital_Left_precision': 0.492619926199262, 'val_Saggital_Left_recall': 0.39035087719298245, 'val_Transverse_Left_f1': 0.41437125748502995, 'val_Transverse_Left_precision': 0.5616883116883117, 'val_Transverse_Left_recall': 0.32827324478178366, 'val_Bladder_f1': 0.7804391217564871, 'val_Bladder_precision': 0.736346516007533, 'val_Bladder_recall': 0.8301486199575372, 'test_precision_average_macro': 0.6188500635595235, 'test_recall_average_macro': 0.5176623529553369, 'test_f1score_average_macro': 0.5427916245215477, 'test_precision_average_micro': 0.5816568047337278, 'test_recall_average_micro': 0.5816568047337278, 'test_f1score_average_micro': 0.5816568047337278, 'test_precision_average_weighted': 0.5961742856530693, 'test_recall_average_weighted': 0.5816568047337278, 'test_f1score_average_weighted': 0.5635009762055353, 'test_acc_average': 0.5816568047337278}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.65      1990\n",
      "           1       0.67      0.40      0.50       790\n",
      "           2       0.71      0.36      0.48       608\n",
      "           3       0.49      0.39      0.44       684\n",
      "           4       0.56      0.33      0.41       527\n",
      "           5       0.74      0.83      0.78       471\n",
      "\n",
      "    accuracy                           0.58      5070\n",
      "   macro avg       0.62      0.52      0.54      5070\n",
      "weighted avg       0.60      0.58      0.56      5070\n",
      "\n",
      "Epoch 17/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0753 | train acc:\t0.5863\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.75      0.65      4943\n",
      "           1       0.63      0.46      0.53      2225\n",
      "           2       0.59      0.36      0.45      1539\n",
      "           3       0.52      0.54      0.53      2284\n",
      "           4       0.53      0.40      0.46      1669\n",
      "           5       0.77      0.79      0.78      1298\n",
      "\n",
      "    accuracy                           0.59     13958\n",
      "   macro avg       0.60      0.55      0.57     13958\n",
      "weighted avg       0.59      0.59      0.58     13958\n",
      "\n",
      "test loss:\t1.2212 | test acc:\t0.5801\n",
      "\n",
      "{'val_Other_f1': 0.6408464763425834, 'val_Other_precision': 0.5316329910566413, 'val_Other_recall': 0.8065326633165829, 'val_Saggital_Right_f1': 0.531039640987285, 'val_Saggital_Right_precision': 0.6489945155393053, 'val_Saggital_Right_recall': 0.44936708860759494, 'val_Transverse_Right_f1': 0.46984126984126984, 'val_Transverse_Right_precision': 0.658753709198813, 'val_Transverse_Right_recall': 0.3651315789473684, 'val_Saggital_Left_f1': 0.41696750902527074, 'val_Saggital_Left_precision': 0.5448113207547169, 'val_Saggital_Left_recall': 0.33771929824561403, 'val_Transverse_Left_f1': 0.34656084656084657, 'val_Transverse_Left_precision': 0.5720524017467249, 'val_Transverse_Left_recall': 0.24857685009487665, 'val_Bladder_f1': 0.8060913705583758, 'val_Bladder_precision': 0.7723735408560312, 'val_Bladder_recall': 0.8428874734607219, 'test_precision_average_macro': 0.6214364131920388, 'test_recall_average_macro': 0.5083691587787932, 'test_f1score_average_macro': 0.5352245188859386, 'test_precision_average_micro': 0.5800788954635109, 'test_recall_average_micro': 0.5800788954635109, 'test_f1score_average_micro': 0.5800788954635109, 'test_precision_average_weighted': 0.5935084953711217, 'test_recall_average_weighted': 0.5800788954635109, 'test_f1score_average_weighted': 0.5577873124672652, 'test_acc_average': 0.5800788954635109}\n",
      "Epoch 18/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0510 | train acc:\t0.5947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.74      0.64      4943\n",
      "           1       0.66      0.49      0.56      2225\n",
      "           2       0.59      0.38      0.47      1539\n",
      "           3       0.53      0.54      0.53      2284\n",
      "           4       0.55      0.43      0.48      1669\n",
      "           5       0.79      0.79      0.79      1298\n",
      "\n",
      "    accuracy                           0.59     13958\n",
      "   macro avg       0.62      0.56      0.58     13958\n",
      "weighted avg       0.60      0.59      0.59     13958\n",
      "\n",
      "test loss:\t1.2208 | test acc:\t0.5669\n",
      "\n",
      "{'val_Other_f1': 0.6189675870348139, 'val_Other_precision': 0.5926436781609196, 'val_Other_recall': 0.6477386934673367, 'val_Saggital_Right_f1': 0.4679841897233202, 'val_Saggital_Right_precision': 0.6231578947368421, 'val_Saggital_Right_recall': 0.37468354430379747, 'val_Transverse_Right_f1': 0.5207700101317122, 'val_Transverse_Right_precision': 0.6781002638522428, 'val_Transverse_Right_recall': 0.42269736842105265, 'val_Saggital_Left_f1': 0.4599999999999999, 'val_Saggital_Left_precision': 0.4017467248908297, 'val_Saggital_Left_recall': 0.5380116959064327, 'val_Transverse_Left_f1': 0.4678150498640073, 'val_Transverse_Left_precision': 0.4479166666666667, 'val_Transverse_Left_recall': 0.48956356736242884, 'val_Bladder_f1': 0.7960784313725491, 'val_Bladder_precision': 0.7395264116575592, 'val_Bladder_recall': 0.861995753715499, 'test_precision_average_macro': 0.58051527332751, 'test_recall_average_macro': 0.5557817705294245, 'test_f1score_average_macro': 0.5552692113544005, 'test_precision_average_micro': 0.5668639053254438, 'test_recall_average_micro': 0.5668639053254438, 'test_f1score_average_micro': 0.5668639053254438, 'test_precision_average_weighted': 0.580493964468219, 'test_recall_average_weighted': 0.5668639053254438, 'test_f1score_average_weighted': 0.5629610742989322, 'test_acc_average': 0.5668639053254438}\n",
      "Epoch 19/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0342 | train acc:\t0.6030\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65      4943\n",
      "           1       0.66      0.49      0.56      2225\n",
      "           2       0.59      0.40      0.48      1539\n",
      "           3       0.54      0.55      0.54      2284\n",
      "           4       0.56      0.44      0.49      1669\n",
      "           5       0.80      0.80      0.80      1298\n",
      "\n",
      "    accuracy                           0.60     13958\n",
      "   macro avg       0.62      0.57      0.59     13958\n",
      "weighted avg       0.61      0.60      0.60     13958\n",
      "\n",
      "test loss:\t1.1861 | test acc:\t0.5807\n",
      "\n",
      "{'val_Other_f1': 0.6330295621249166, 'val_Other_precision': 0.5675567955360702, 'val_Other_recall': 0.7155778894472362, 'val_Saggital_Right_f1': 0.5483028720626631, 'val_Saggital_Right_precision': 0.5660377358490566, 'val_Saggital_Right_recall': 0.5316455696202531, 'val_Transverse_Right_f1': 0.4930032292787944, 'val_Transverse_Right_precision': 0.7133956386292835, 'val_Transverse_Right_recall': 0.37664473684210525, 'val_Saggital_Left_f1': 0.42775510204081635, 'val_Saggital_Left_precision': 0.48428835489833644, 'val_Saggital_Left_recall': 0.3830409356725146, 'val_Transverse_Left_f1': 0.4578790882061447, 'val_Transverse_Left_precision': 0.47925311203319504, 'val_Transverse_Left_recall': 0.43833017077798864, 'val_Bladder_f1': 0.799154334038055, 'val_Bladder_precision': 0.7957894736842105, 'val_Bladder_recall': 0.802547770700637, 'test_precision_average_macro': 0.6010535184383587, 'test_recall_average_macro': 0.5412978455101225, 'test_f1score_average_macro': 0.5598540312918984, 'test_precision_average_micro': 0.5806706114398422, 'test_recall_average_micro': 0.5806706114398422, 'test_f1score_average_micro': 0.5806706114398422, 'test_precision_average_weighted': 0.585599378623542, 'test_recall_average_weighted': 0.5806706114398422, 'test_f1score_average_weighted': 0.5725685446887723, 'test_acc_average': 0.5806706114398422}\n",
      "Epoch 20/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t1.0316 | train acc:\t0.6034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      4943\n",
      "           1       0.65      0.50      0.56      2225\n",
      "           2       0.61      0.41      0.49      1539\n",
      "           3       0.54      0.54      0.54      2284\n",
      "           4       0.56      0.45      0.50      1669\n",
      "           5       0.78      0.79      0.79      1298\n",
      "\n",
      "    accuracy                           0.60     13958\n",
      "   macro avg       0.62      0.57      0.59     13958\n",
      "weighted avg       0.61      0.60      0.60     13958\n",
      "\n",
      "test loss:\t1.1721 | test acc:\t0.5876\n",
      "\n",
      "{'val_Other_f1': 0.6363008971704623, 'val_Other_precision': 0.5867628341111583, 'val_Other_recall': 0.6949748743718593, 'val_Saggital_Right_f1': 0.5410764872521246, 'val_Saggital_Right_precision': 0.6141479099678456, 'val_Saggital_Right_recall': 0.4835443037974684, 'val_Transverse_Right_f1': 0.5528301886792453, 'val_Transverse_Right_precision': 0.6482300884955752, 'val_Transverse_Right_recall': 0.4819078947368421, 'val_Saggital_Left_f1': 0.42362869198312236, 'val_Saggital_Left_precision': 0.500998003992016, 'val_Saggital_Left_recall': 0.3669590643274854, 'val_Transverse_Left_f1': 0.4787714543812105, 'val_Transverse_Left_precision': 0.45689655172413796, 'val_Transverse_Left_recall': 0.5028462998102466, 'val_Bladder_f1': 0.7871720116618076, 'val_Bladder_precision': 0.7258064516129032, 'val_Bladder_recall': 0.8598726114649682, 'test_precision_average_macro': 0.5888069733172726, 'test_recall_average_macro': 0.5650175080848118, 'test_f1score_average_macro': 0.5699632885213287, 'test_precision_average_micro': 0.5875739644970415, 'test_recall_average_micro': 0.5875739644970415, 'test_f1score_average_micro': 0.5875739644970415, 'test_precision_average_weighted': 0.5862486664220808, 'test_recall_average_weighted': 0.5875739644970415, 'test_f1score_average_weighted': 0.5804028726397327, 'test_acc_average': 0.5875739644970415}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.64      1990\n",
      "           1       0.61      0.48      0.54       790\n",
      "           2       0.65      0.48      0.55       608\n",
      "           3       0.50      0.37      0.42       684\n",
      "           4       0.46      0.50      0.48       527\n",
      "           5       0.73      0.86      0.79       471\n",
      "\n",
      "    accuracy                           0.59      5070\n",
      "   macro avg       0.59      0.57      0.57      5070\n",
      "weighted avg       0.59      0.59      0.58      5070\n",
      "\n",
      "Epoch 21/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0233 | train acc:\t0.6073\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      4943\n",
      "           1       0.65      0.50      0.57      2225\n",
      "           2       0.63      0.41      0.50      1539\n",
      "           3       0.55      0.55      0.55      2284\n",
      "           4       0.55      0.45      0.50      1669\n",
      "           5       0.80      0.80      0.80      1298\n",
      "\n",
      "    accuracy                           0.61     13958\n",
      "   macro avg       0.63      0.58      0.59     13958\n",
      "weighted avg       0.61      0.61      0.60     13958\n",
      "\n",
      "test loss:\t1.1982 | test acc:\t0.5874\n",
      "\n",
      "{'val_Other_f1': 0.6505118027992479, 'val_Other_precision': 0.5566678584197354, 'val_Other_recall': 0.7824120603015076, 'val_Saggital_Right_f1': 0.4884105960264901, 'val_Saggital_Right_precision': 0.7057416267942583, 'val_Saggital_Right_recall': 0.37341772151898733, 'val_Transverse_Right_f1': 0.4936170212765958, 'val_Transverse_Right_precision': 0.6987951807228916, 'val_Transverse_Right_recall': 0.3815789473684211, 'val_Saggital_Left_f1': 0.4494569757727652, 'val_Saggital_Left_precision': 0.5243664717348928, 'val_Saggital_Left_recall': 0.3932748538011696, 'val_Transverse_Left_f1': 0.45821042281219276, 'val_Transverse_Left_precision': 0.47551020408163264, 'val_Transverse_Left_recall': 0.44212523719165087, 'val_Bladder_f1': 0.7911200807265388, 'val_Bladder_precision': 0.7538461538461538, 'val_Bladder_recall': 0.832271762208068, 'test_precision_average_macro': 0.6191545825999275, 'test_recall_average_macro': 0.5341800970649674, 'test_f1score_average_macro': 0.5552211499023051, 'test_precision_average_micro': 0.5873767258382643, 'test_recall_average_micro': 0.5873767258382643, 'test_f1score_average_micro': 0.5873767258382643, 'test_precision_average_weighted': 0.6024643936847103, 'test_recall_average_weighted': 0.5873767258382643, 'test_f1score_average_weighted': 0.5723875798107293, 'test_acc_average': 0.5873767258382643}\n",
      "Epoch 22/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0114 | train acc:\t0.6105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66      4943\n",
      "           1       0.66      0.50      0.57      2225\n",
      "           2       0.61      0.43      0.50      1539\n",
      "           3       0.55      0.55      0.55      2284\n",
      "           4       0.56      0.44      0.50      1669\n",
      "           5       0.80      0.81      0.80      1298\n",
      "\n",
      "    accuracy                           0.61     13958\n",
      "   macro avg       0.63      0.58      0.60     13958\n",
      "weighted avg       0.61      0.61      0.60     13958\n",
      "\n",
      "test loss:\t1.2272 | test acc:\t0.5750\n",
      "\n",
      "{'val_Other_f1': 0.6163040879751375, 'val_Other_precision': 0.5877792977656179, 'val_Other_recall': 0.6477386934673367, 'val_Saggital_Right_f1': 0.5274725274725275, 'val_Saggital_Right_precision': 0.6260869565217392, 'val_Saggital_Right_recall': 0.45569620253164556, 'val_Transverse_Right_f1': 0.5473684210526316, 'val_Transverse_Right_precision': 0.6544622425629291, 'val_Transverse_Right_recall': 0.47039473684210525, 'val_Saggital_Left_f1': 0.4434845212383009, 'val_Saggital_Left_precision': 0.4368794326241135, 'val_Saggital_Left_recall': 0.4502923976608187, 'val_Transverse_Left_f1': 0.4748700173310225, 'val_Transverse_Left_precision': 0.4370015948963317, 'val_Transverse_Left_recall': 0.5199240986717267, 'val_Bladder_f1': 0.7928286852589641, 'val_Bladder_precision': 0.7467166979362101, 'val_Bladder_recall': 0.8450106157112527, 'test_precision_average_macro': 0.5814877037178237, 'test_recall_average_macro': 0.5648427908141476, 'test_f1score_average_macro': 0.567054710054764, 'test_precision_average_micro': 0.5749506903353058, 'test_recall_average_micro': 0.5749506903353058, 'test_f1score_average_micro': 0.5749506903353058, 'test_precision_average_weighted': 0.5804795816247001, 'test_recall_average_weighted': 0.5749506903353058, 'test_f1score_average_weighted': 0.5725780383020195, 'test_acc_average': 0.5749506903353058}\n",
      "Epoch 23/46\n",
      "------------------------------------------------------\n",
      "train loss:\t1.0050 | train acc:\t0.6131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.66      4943\n",
      "           1       0.65      0.51      0.57      2225\n",
      "           2       0.62      0.43      0.51      1539\n",
      "           3       0.55      0.55      0.55      2284\n",
      "           4       0.57      0.47      0.51      1669\n",
      "           5       0.80      0.80      0.80      1298\n",
      "\n",
      "    accuracy                           0.61     13958\n",
      "   macro avg       0.63      0.58      0.60     13958\n",
      "weighted avg       0.62      0.61      0.61     13958\n",
      "\n",
      "test loss:\t1.1858 | test acc:\t0.5807\n",
      "\n",
      "{'val_Other_f1': 0.6316510618862755, 'val_Other_precision': 0.5789033068229384, 'val_Other_recall': 0.6949748743718593, 'val_Saggital_Right_f1': 0.5373134328358209, 'val_Saggital_Right_precision': 0.5789473684210527, 'val_Saggital_Right_recall': 0.5012658227848101, 'val_Transverse_Right_f1': 0.5459770114942528, 'val_Transverse_Right_precision': 0.6536697247706422, 'val_Transverse_Right_recall': 0.46875, 'val_Saggital_Left_f1': 0.4436997319034852, 'val_Saggital_Left_precision': 0.40965346534653463, 'val_Saggital_Left_recall': 0.48391812865497075, 'val_Transverse_Left_f1': 0.4158415841584158, 'val_Transverse_Left_precision': 0.597864768683274, 'val_Transverse_Left_recall': 0.3187855787476281, 'val_Bladder_f1': 0.8080593849416755, 'val_Bladder_precision': 0.8072033898305084, 'val_Bladder_recall': 0.8089171974522293, 'test_precision_average_macro': 0.604373670645825, 'test_recall_average_macro': 0.546101933668583, 'test_f1score_average_macro': 0.5637570345366543, 'test_precision_average_micro': 0.5806706114398422, 'test_recall_average_micro': 0.5806706114398422, 'test_f1score_average_micro': 0.5806706114398422, 'test_precision_average_weighted': 0.5882224249100817, 'test_recall_average_weighted': 0.5806706114398422, 'test_f1score_average_weighted': 0.5752765976062112, 'test_acc_average': 0.5806706114398422}\n",
      "Epoch 24/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t0.9913 | train acc:\t0.6201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      4943\n",
      "           1       0.67      0.51      0.58      2225\n",
      "           2       0.63      0.44      0.52      1539\n",
      "           3       0.56      0.55      0.55      2284\n",
      "           4       0.58      0.49      0.53      1669\n",
      "           5       0.80      0.81      0.80      1298\n",
      "\n",
      "    accuracy                           0.62     13958\n",
      "   macro avg       0.64      0.59      0.61     13958\n",
      "weighted avg       0.62      0.62      0.61     13958\n",
      "\n",
      "test loss:\t1.1419 | test acc:\t0.5860\n",
      "\n",
      "{'val_Other_f1': 0.6485484867201976, 'val_Other_precision': 0.5493547261946286, 'val_Other_recall': 0.7914572864321608, 'val_Saggital_Right_f1': 0.528328611898017, 'val_Saggital_Right_precision': 0.5996784565916399, 'val_Saggital_Right_recall': 0.47215189873417723, 'val_Transverse_Right_f1': 0.4646924829157176, 'val_Transverse_Right_precision': 0.7555555555555555, 'val_Transverse_Right_recall': 0.3355263157894737, 'val_Saggital_Left_f1': 0.4338172502134927, 'val_Saggital_Left_precision': 0.5215605749486653, 'val_Saggital_Left_recall': 0.3713450292397661, 'val_Transverse_Left_f1': 0.4284128745837958, 'val_Transverse_Left_precision': 0.516042780748663, 'val_Transverse_Left_recall': 0.36622390891840606, 'val_Bladder_f1': 0.8078175895765471, 'val_Bladder_precision': 0.8266666666666667, 'val_Bladder_recall': 0.7898089171974523, 'test_precision_average_macro': 0.6281431267843032, 'test_recall_average_macro': 0.5210855593852394, 'test_f1score_average_macro': 0.5519362159846279, 'test_precision_average_micro': 0.5859960552268244, 'test_recall_average_micro': 0.5859960552268244, 'test_f1score_average_micro': 0.5859960552268244, 'test_precision_average_weighted': 0.6004736967124096, 'test_recall_average_weighted': 0.5859960552268244, 'test_f1score_average_weighted': 0.5707121874413463, 'test_acc_average': 0.5859960552268244}\n",
      "Epoch 25/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9783 | train acc:\t0.6249\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.67      4943\n",
      "           1       0.67      0.53      0.59      2225\n",
      "           2       0.63      0.44      0.52      1539\n",
      "           3       0.57      0.55      0.56      2284\n",
      "           4       0.57      0.49      0.53      1669\n",
      "           5       0.79      0.81      0.80      1298\n",
      "\n",
      "    accuracy                           0.62     13958\n",
      "   macro avg       0.64      0.60      0.61     13958\n",
      "weighted avg       0.63      0.62      0.62     13958\n",
      "\n",
      "test loss:\t1.1790 | test acc:\t0.5781\n",
      "\n",
      "{'val_Other_f1': 0.6181130290848901, 'val_Other_precision': 0.5837427422956677, 'val_Other_recall': 0.65678391959799, 'val_Saggital_Right_f1': 0.5286885245901639, 'val_Saggital_Right_precision': 0.5741839762611276, 'val_Saggital_Right_recall': 0.489873417721519, 'val_Transverse_Right_f1': 0.5817843866171004, 'val_Transverse_Right_precision': 0.6688034188034188, 'val_Transverse_Right_recall': 0.5148026315789473, 'val_Saggital_Left_f1': 0.4631147540983606, 'val_Saggital_Left_precision': 0.4346153846153846, 'val_Saggital_Left_recall': 0.4956140350877193, 'val_Transverse_Left_f1': 0.4658077304261646, 'val_Transverse_Left_precision': 0.487551867219917, 'val_Transverse_Left_recall': 0.4459203036053131, 'val_Bladder_f1': 0.779510022271715, 'val_Bladder_precision': 0.819672131147541, 'val_Bladder_recall': 0.7430997876857749, 'test_precision_average_macro': 0.5947615867238427, 'test_recall_average_macro': 0.5576823492128772, 'test_f1score_average_macro': 0.5728364078480658, 'test_precision_average_micro': 0.5781065088757397, 'test_recall_average_micro': 0.5781065088757397, 'test_f1score_average_micro': 0.5781065088757397, 'test_precision_average_weighted': 0.5842540844022602, 'test_recall_average_weighted': 0.5781065088757397, 'test_f1score_average_weighted': 0.578073797947969, 'test_acc_average': 0.5781065088757397}\n",
      "Epoch 26/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9730 | train acc:\t0.6287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.67      4943\n",
      "           1       0.68      0.52      0.59      2225\n",
      "           2       0.62      0.45      0.52      1539\n",
      "           3       0.57      0.58      0.58      2284\n",
      "           4       0.59      0.49      0.53      1669\n",
      "           5       0.81      0.81      0.81      1298\n",
      "\n",
      "    accuracy                           0.63     13958\n",
      "   macro avg       0.65      0.60      0.62     13958\n",
      "weighted avg       0.63      0.63      0.62     13958\n",
      "\n",
      "test loss:\t1.1913 | test acc:\t0.5826\n",
      "\n",
      "{'val_Other_f1': 0.6260257913247362, 'val_Other_precision': 0.5868131868131868, 'val_Other_recall': 0.6708542713567839, 'val_Saggital_Right_f1': 0.534494306764903, 'val_Saggital_Right_precision': 0.5675675675675675, 'val_Saggital_Right_recall': 0.5050632911392405, 'val_Transverse_Right_f1': 0.5743119266055046, 'val_Transverse_Right_precision': 0.6493775933609959, 'val_Transverse_Right_recall': 0.5148026315789473, 'val_Saggital_Left_f1': 0.4638069705093834, 'val_Saggital_Left_precision': 0.4282178217821782, 'val_Saggital_Left_recall': 0.5058479532163743, 'val_Transverse_Left_f1': 0.4270952927669346, 'val_Transverse_Left_precision': 0.5406976744186046, 'val_Transverse_Left_recall': 0.35294117647058826, 'val_Bladder_f1': 0.8073196986006458, 'val_Bladder_precision': 0.8187772925764192, 'val_Bladder_recall': 0.7961783439490446, 'test_precision_average_macro': 0.5985751894198255, 'test_recall_average_macro': 0.5576146112851632, 'test_f1score_average_macro': 0.5721756644286846, 'test_precision_average_micro': 0.5826429980276134, 'test_recall_average_micro': 0.5826429980276134, 'test_f1score_average_micro': 0.5826429980276134, 'test_precision_average_weighted': 0.5866767191757818, 'test_recall_average_weighted': 0.5826429980276134, 'test_f1score_average_weighted': 0.5798410736911522, 'test_acc_average': 0.5826429980276134}\n",
      "Epoch 27/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9574 | train acc:\t0.6339\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68      4943\n",
      "           1       0.68      0.53      0.60      2225\n",
      "           2       0.62      0.47      0.53      1539\n",
      "           3       0.57      0.58      0.58      2284\n",
      "           4       0.60      0.50      0.54      1669\n",
      "           5       0.82      0.82      0.82      1298\n",
      "\n",
      "    accuracy                           0.63     13958\n",
      "   macro avg       0.65      0.61      0.62     13958\n",
      "weighted avg       0.64      0.63      0.63     13958\n",
      "\n",
      "test loss:\t1.1744 | test acc:\t0.5799\n",
      "\n",
      "{'val_Other_f1': 0.6393819168928795, 'val_Other_precision': 0.5469810646659521, 'val_Other_recall': 0.7693467336683417, 'val_Saggital_Right_f1': 0.49136577708006285, 'val_Saggital_Right_precision': 0.6466942148760331, 'val_Saggital_Right_recall': 0.3962025316455696, 'val_Transverse_Right_f1': 0.44417767106842737, 'val_Transverse_Right_precision': 0.8222222222222222, 'val_Transverse_Right_recall': 0.3042763157894737, 'val_Saggital_Left_f1': 0.4727272727272727, 'val_Saggital_Left_precision': 0.4703328509406657, 'val_Saggital_Left_recall': 0.47514619883040937, 'val_Transverse_Left_f1': 0.43600867678958793, 'val_Transverse_Left_precision': 0.5088607594936709, 'val_Transverse_Left_recall': 0.38140417457305503, 'val_Bladder_f1': 0.8130939809926082, 'val_Bladder_precision': 0.8088235294117647, 'val_Bladder_recall': 0.8174097664543525, 'test_precision_average_macro': 0.6339857736017181, 'test_recall_average_macro': 0.5239642868268669, 'test_f1score_average_macro': 0.5494592159251398, 'test_precision_average_micro': 0.5798816568047337, 'test_recall_average_micro': 0.5798816568047337, 'test_f1score_average_micro': 0.5798816568047337, 'test_precision_average_weighted': 0.6055473436287856, 'test_recall_average_weighted': 0.5798816568047337, 'test_f1score_average_weighted': 0.5654237267812169, 'test_acc_average': 0.5798816568047337}\n",
      "Epoch 28/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9563 | train acc:\t0.6371\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68      4943\n",
      "           1       0.69      0.54      0.61      2225\n",
      "           2       0.64      0.46      0.53      1539\n",
      "           3       0.58      0.58      0.58      2284\n",
      "           4       0.58      0.51      0.54      1669\n",
      "           5       0.82      0.82      0.82      1298\n",
      "\n",
      "    accuracy                           0.64     13958\n",
      "   macro avg       0.66      0.61      0.63     13958\n",
      "weighted avg       0.64      0.64      0.63     13958\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:\t1.1627 | test acc:\t0.5929\n",
      "\n",
      "{'val_Other_f1': 0.6456725755995829, 'val_Other_precision': 0.5518716577540107, 'val_Other_recall': 0.7778894472361809, 'val_Saggital_Right_f1': 0.5416974169741697, 'val_Saggital_Right_precision': 0.6495575221238938, 'val_Saggital_Right_recall': 0.46455696202531643, 'val_Transverse_Right_f1': 0.5380493033226154, 'val_Transverse_Right_precision': 0.7723076923076924, 'val_Transverse_Right_recall': 0.4128289473684211, 'val_Saggital_Left_f1': 0.4404567699836868, 'val_Saggital_Left_precision': 0.4981549815498155, 'val_Saggital_Left_recall': 0.39473684210526316, 'val_Transverse_Left_f1': 0.4514038876889849, 'val_Transverse_Left_precision': 0.5238095238095238, 'val_Transverse_Left_recall': 0.396584440227704, 'val_Bladder_f1': 0.7977900552486188, 'val_Bladder_precision': 0.8317972350230415, 'val_Bladder_recall': 0.7664543524416136, 'test_precision_average_macro': 0.6379164354279963, 'test_recall_average_macro': 0.5355084985674164, 'test_f1score_average_macro': 0.5691783348029431, 'test_precision_average_micro': 0.5928994082840237, 'test_recall_average_micro': 0.5928994082840237, 'test_f1score_average_micro': 0.5928994082840237, 'test_precision_average_weighted': 0.6093688841134082, 'test_recall_average_weighted': 0.5928994082840237, 'test_f1score_average_weighted': 0.5828175062674459, 'test_acc_average': 0.5928994082840237}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.65      1990\n",
      "           1       0.65      0.46      0.54       790\n",
      "           2       0.77      0.41      0.54       608\n",
      "           3       0.50      0.39      0.44       684\n",
      "           4       0.52      0.40      0.45       527\n",
      "           5       0.83      0.77      0.80       471\n",
      "\n",
      "    accuracy                           0.59      5070\n",
      "   macro avg       0.64      0.54      0.57      5070\n",
      "weighted avg       0.61      0.59      0.58      5070\n",
      "\n",
      "Epoch 29/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9391 | train acc:\t0.6378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68      4943\n",
      "           1       0.68      0.54      0.60      2225\n",
      "           2       0.65      0.47      0.55      1539\n",
      "           3       0.58      0.57      0.57      2284\n",
      "           4       0.59      0.50      0.54      1669\n",
      "           5       0.82      0.83      0.82      1298\n",
      "\n",
      "    accuracy                           0.64     13958\n",
      "   macro avg       0.66      0.61      0.63     13958\n",
      "weighted avg       0.64      0.64      0.63     13958\n",
      "\n",
      "test loss:\t1.1590 | test acc:\t0.5874\n",
      "\n",
      "{'val_Other_f1': 0.6243715585348336, 'val_Other_precision': 0.5962505715592136, 'val_Other_recall': 0.6552763819095477, 'val_Saggital_Right_f1': 0.5459459459459458, 'val_Saggital_Right_precision': 0.5855072463768116, 'val_Saggital_Right_recall': 0.5113924050632911, 'val_Transverse_Right_f1': 0.5786407766990291, 'val_Transverse_Right_precision': 0.7061611374407583, 'val_Transverse_Right_recall': 0.4901315789473684, 'val_Saggital_Left_f1': 0.47952443857331567, 'val_Saggital_Left_precision': 0.43734939759036146, 'val_Saggital_Left_recall': 0.5307017543859649, 'val_Transverse_Left_f1': 0.4720861900097943, 'val_Transverse_Left_precision': 0.48785425101214575, 'val_Transverse_Left_recall': 0.4573055028462998, 'val_Bladder_f1': 0.8017429193899783, 'val_Bladder_precision': 0.8232662192393736, 'val_Bladder_recall': 0.7813163481953291, 'test_precision_average_macro': 0.6060648038697773, 'test_recall_average_macro': 0.5710206618913002, 'test_f1score_average_macro': 0.5837186381921494, 'test_precision_average_micro': 0.5873767258382643, 'test_recall_average_micro': 0.5873767258382643, 'test_f1score_average_micro': 0.5873767258382643, 'test_precision_average_weighted': 0.5961419923277023, 'test_recall_average_weighted': 0.5873767258382643, 'test_f1score_average_weighted': 0.5877742296186619, 'test_acc_average': 0.5873767258382643}\n",
      "Epoch 30/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9421 | train acc:\t0.6448\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69      4943\n",
      "           1       0.70      0.55      0.62      2225\n",
      "           2       0.65      0.48      0.55      1539\n",
      "           3       0.58      0.58      0.58      2284\n",
      "           4       0.60      0.51      0.56      1669\n",
      "           5       0.81      0.83      0.82      1298\n",
      "\n",
      "    accuracy                           0.64     13958\n",
      "   macro avg       0.66      0.62      0.63     13958\n",
      "weighted avg       0.65      0.64      0.64     13958\n",
      "\n",
      "test loss:\t1.1543 | test acc:\t0.5892\n",
      "\n",
      "{'val_Other_f1': 0.6232489555173262, 'val_Other_precision': 0.60990860990861, 'val_Other_recall': 0.6371859296482412, 'val_Saggital_Right_f1': 0.5247524752475248, 'val_Saggital_Right_precision': 0.594551282051282, 'val_Saggital_Right_recall': 0.46962025316455697, 'val_Transverse_Right_f1': 0.6017699115044247, 'val_Transverse_Right_precision': 0.6513409961685823, 'val_Transverse_Right_recall': 0.5592105263157895, 'val_Saggital_Left_f1': 0.4705093833780162, 'val_Saggital_Left_precision': 0.4344059405940594, 'val_Saggital_Left_recall': 0.5131578947368421, 'val_Transverse_Left_f1': 0.49536178107606677, 'val_Transverse_Left_precision': 0.484573502722323, 'val_Transverse_Left_recall': 0.5066413662239089, 'val_Bladder_f1': 0.8150470219435737, 'val_Bladder_precision': 0.8024691358024691, 'val_Bladder_recall': 0.8280254777070064, 'test_precision_average_macro': 0.596208244541221, 'test_recall_average_macro': 0.5856402412993909, 'test_f1score_average_macro': 0.588448254777822, 'test_precision_average_micro': 0.5891518737672584, 'test_recall_average_micro': 0.5891518737672584, 'test_f1score_average_micro': 0.5891518737672584, 'test_precision_average_weighted': 0.5936678174503174, 'test_recall_average_weighted': 0.5891518737672584, 'test_f1score_average_weighted': 0.5892440251110035, 'test_acc_average': 0.5891518737672584}\n",
      "Epoch 31/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9222 | train acc:\t0.6482\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69      4943\n",
      "           1       0.70      0.55      0.61      2225\n",
      "           2       0.66      0.50      0.57      1539\n",
      "           3       0.59      0.58      0.59      2284\n",
      "           4       0.61      0.53      0.56      1669\n",
      "           5       0.83      0.83      0.83      1298\n",
      "\n",
      "    accuracy                           0.65     13958\n",
      "   macro avg       0.67      0.62      0.64     13958\n",
      "weighted avg       0.65      0.65      0.64     13958\n",
      "\n",
      "test loss:\t1.1462 | test acc:\t0.5771\n",
      "\n",
      "{'val_Other_f1': 0.6234989404285378, 'val_Other_precision': 0.5866194062915374, 'val_Other_recall': 0.6653266331658292, 'val_Saggital_Right_f1': 0.5528781793842035, 'val_Saggital_Right_precision': 0.5866477272727273, 'val_Saggital_Right_recall': 0.5227848101265823, 'val_Transverse_Right_f1': 0.5148305084745763, 'val_Transverse_Right_precision': 0.7232142857142857, 'val_Transverse_Right_recall': 0.3996710526315789, 'val_Saggital_Left_f1': 0.4575325480471172, 'val_Saggital_Left_precision': 0.39720129171151775, 'val_Saggital_Left_recall': 0.5394736842105263, 'val_Transverse_Left_f1': 0.43832599118942733, 'val_Transverse_Left_precision': 0.5223097112860893, 'val_Transverse_Left_recall': 0.3776091081593928, 'val_Bladder_f1': 0.809421841541756, 'val_Bladder_precision': 0.816414686825054, 'val_Bladder_recall': 0.802547770700637, 'test_precision_average_macro': 0.605401184850202, 'test_recall_average_macro': 0.5512355098324244, 'test_f1score_average_macro': 0.5660813348442697, 'test_precision_average_micro': 0.5771203155818541, 'test_recall_average_micro': 0.5771203155818541, 'test_f1score_average_micro': 0.5771203155818541, 'test_precision_average_weighted': 0.5921129837579777, 'test_recall_average_weighted': 0.5771203155818541, 'test_f1score_average_weighted': 0.5750969131964648, 'test_acc_average': 0.5771203155818541}\n",
      "Epoch 32/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9262 | train acc:\t0.6435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68      4943\n",
      "           1       0.69      0.55      0.62      2225\n",
      "           2       0.66      0.50      0.57      1539\n",
      "           3       0.58      0.58      0.58      2284\n",
      "           4       0.60      0.50      0.54      1669\n",
      "           5       0.82      0.84      0.83      1298\n",
      "\n",
      "    accuracy                           0.64     13958\n",
      "   macro avg       0.66      0.62      0.64     13958\n",
      "weighted avg       0.65      0.64      0.64     13958\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:\t1.1392 | test acc:\t0.5949\n",
      "\n",
      "{'val_Other_f1': 0.6296470588235294, 'val_Other_precision': 0.5920353982300885, 'val_Other_recall': 0.6723618090452261, 'val_Saggital_Right_f1': 0.5612316305108467, 'val_Saggital_Right_precision': 0.6275430359937402, 'val_Saggital_Right_recall': 0.5075949367088608, 'val_Transverse_Right_f1': 0.595581171950048, 'val_Transverse_Right_precision': 0.7159353348729792, 'val_Transverse_Right_recall': 0.5098684210526315, 'val_Saggital_Left_f1': 0.4668508287292818, 'val_Saggital_Left_precision': 0.4424083769633508, 'val_Saggital_Left_recall': 0.49415204678362573, 'val_Transverse_Left_f1': 0.4888457807953443, 'val_Transverse_Left_precision': 0.5, 'val_Transverse_Left_recall': 0.4781783681214421, 'val_Bladder_f1': 0.8012752391073327, 'val_Bladder_precision': 0.8021276595744681, 'val_Bladder_recall': 0.8004246284501062, 'test_precision_average_macro': 0.6133416342724377, 'test_recall_average_macro': 0.5770967016936487, 'test_f1score_average_macro': 0.5905719516527305, 'test_precision_average_micro': 0.5948717948717949, 'test_recall_average_micro': 0.5948717948717949, 'test_f1score_average_micro': 0.5948717948717949, 'test_precision_average_weighted': 0.6021908445795283, 'test_recall_average_weighted': 0.5948717948717949, 'test_f1score_average_weighted': 0.5942470056523769, 'test_acc_average': 0.5948717948717949}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63      1990\n",
      "           1       0.63      0.51      0.56       790\n",
      "           2       0.72      0.51      0.60       608\n",
      "           3       0.44      0.49      0.47       684\n",
      "           4       0.50      0.48      0.49       527\n",
      "           5       0.80      0.80      0.80       471\n",
      "\n",
      "    accuracy                           0.59      5070\n",
      "   macro avg       0.61      0.58      0.59      5070\n",
      "weighted avg       0.60      0.59      0.59      5070\n",
      "\n",
      "Epoch 33/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9154 | train acc:\t0.6522\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69      4943\n",
      "           1       0.69      0.56      0.62      2225\n",
      "           2       0.67      0.50      0.57      1539\n",
      "           3       0.60      0.59      0.59      2284\n",
      "           4       0.61      0.54      0.57      1669\n",
      "           5       0.82      0.82      0.82      1298\n",
      "\n",
      "    accuracy                           0.65     13958\n",
      "   macro avg       0.67      0.63      0.64     13958\n",
      "weighted avg       0.65      0.65      0.65     13958\n",
      "\n",
      "test loss:\t1.1753 | test acc:\t0.5759\n",
      "\n",
      "{'val_Other_f1': 0.6097930338213023, 'val_Other_precision': 0.6125760649087221, 'val_Other_recall': 0.607035175879397, 'val_Saggital_Right_f1': 0.49247822644497224, 'val_Saggital_Right_precision': 0.6575052854122622, 'val_Saggital_Right_recall': 0.39367088607594936, 'val_Transverse_Right_f1': 0.5950128976784178, 'val_Transverse_Right_precision': 0.6234234234234234, 'val_Transverse_Right_recall': 0.569078947368421, 'val_Saggital_Left_f1': 0.46826347305389227, 'val_Saggital_Left_precision': 0.39655172413793105, 'val_Saggital_Left_recall': 0.5716374269005848, 'val_Transverse_Left_f1': 0.49373881932021463, 'val_Transverse_Left_precision': 0.467005076142132, 'val_Transverse_Left_recall': 0.523719165085389, 'val_Bladder_f1': 0.8049792531120333, 'val_Bladder_precision': 0.7870182555780934, 'val_Bladder_recall': 0.8237791932059448, 'test_precision_average_macro': 0.5906799716004274, 'test_recall_average_macro': 0.5814867990859476, 'test_f1score_average_macro': 0.5773776172384721, 'test_precision_average_micro': 0.5759368836291914, 'test_recall_average_micro': 0.5759368836291914, 'test_f1score_average_micro': 0.5759368836291914, 'test_precision_average_weighted': 0.5928078183234745, 'test_recall_average_weighted': 0.5759368836291914, 'test_f1score_average_weighted': 0.5767162878798385, 'test_acc_average': 0.5759368836291914}\n",
      "Epoch 34/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9069 | train acc:\t0.6531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69      4943\n",
      "           1       0.69      0.54      0.61      2225\n",
      "           2       0.66      0.53      0.59      1539\n",
      "           3       0.59      0.59      0.59      2284\n",
      "           4       0.62      0.54      0.58      1669\n",
      "           5       0.82      0.83      0.83      1298\n",
      "\n",
      "    accuracy                           0.65     13958\n",
      "   macro avg       0.67      0.63      0.65     13958\n",
      "weighted avg       0.66      0.65      0.65     13958\n",
      "\n",
      "test loss:\t1.1680 | test acc:\t0.5886\n",
      "\n",
      "{'val_Other_f1': 0.6234684260131952, 'val_Other_precision': 0.5869565217391305, 'val_Other_recall': 0.6648241206030151, 'val_Saggital_Right_f1': 0.5518188057652711, 'val_Saggital_Right_precision': 0.6026986506746627, 'val_Saggital_Right_recall': 0.5088607594936709, 'val_Transverse_Right_f1': 0.5405405405405405, 'val_Transverse_Right_precision': 0.7344632768361582, 'val_Transverse_Right_recall': 0.4276315789473684, 'val_Saggital_Left_f1': 0.4837209302325582, 'val_Saggital_Left_precision': 0.44336175395858707, 'val_Saggital_Left_recall': 0.5321637426900585, 'val_Transverse_Left_f1': 0.4878522837706511, 'val_Transverse_Left_precision': 0.5, 'val_Transverse_Left_recall': 0.476280834914611, 'val_Bladder_f1': 0.8144220572640509, 'val_Bladder_precision': 0.8135593220338984, 'val_Bladder_recall': 0.8152866242038217, 'test_precision_average_macro': 0.6135065875404061, 'test_recall_average_macro': 0.5708412768087575, 'test_f1score_average_macro': 0.5836371739310444, 'test_precision_average_micro': 0.5885601577909271, 'test_recall_average_micro': 0.5885601577909271, 'test_f1score_average_micro': 0.5885601577909271, 'test_precision_average_weighted': 0.599738651872954, 'test_recall_average_weighted': 0.5885601577909271, 'test_f1score_average_weighted': 0.5871486650428092, 'test_acc_average': 0.5885601577909271}\n",
      "Epoch 35/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8962 | train acc:\t0.6623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70      4943\n",
      "           1       0.71      0.57      0.63      2225\n",
      "           2       0.69      0.52      0.59      1539\n",
      "           3       0.60      0.60      0.60      2284\n",
      "           4       0.62      0.54      0.58      1669\n",
      "           5       0.83      0.83      0.83      1298\n",
      "\n",
      "    accuracy                           0.66     13958\n",
      "   macro avg       0.68      0.64      0.66     13958\n",
      "weighted avg       0.67      0.66      0.66     13958\n",
      "\n",
      "test loss:\t1.1130 | test acc:\t0.6057\n",
      "\n",
      "{'val_Other_f1': 0.6448850833708878, 'val_Other_precision': 0.5845588235294118, 'val_Other_recall': 0.7190954773869347, 'val_Saggital_Right_f1': 0.5786082474226805, 'val_Saggital_Right_precision': 0.589238845144357, 'val_Saggital_Right_recall': 0.5683544303797469, 'val_Transverse_Right_f1': 0.6056338028169014, 'val_Transverse_Right_precision': 0.6515151515151515, 'val_Transverse_Right_recall': 0.5657894736842105, 'val_Saggital_Left_f1': 0.45203252032520325, 'val_Saggital_Left_precision': 0.5091575091575091, 'val_Saggital_Left_recall': 0.4064327485380117, 'val_Transverse_Left_f1': 0.4418331374853114, 'val_Transverse_Left_precision': 0.5802469135802469, 'val_Transverse_Left_recall': 0.3567362428842505, 'val_Bladder_f1': 0.8167202572347266, 'val_Bladder_precision': 0.8246753246753247, 'val_Bladder_recall': 0.8089171974522293, 'test_precision_average_macro': 0.6232320946003335, 'test_recall_average_macro': 0.5708875950542306, 'test_f1score_average_macro': 0.5899521747759519, 'test_precision_average_micro': 0.6057199211045365, 'test_recall_average_micro': 0.6057199211045365, 'test_f1score_average_micro': 0.6057199211045365, 'test_precision_average_weighted': 0.6050035298326208, 'test_recall_average_weighted': 0.6057199211045365, 'test_f1score_average_weighted': 0.5986900852069851, 'test_acc_average': 0.6057199211045365}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.72      0.64      1990\n",
      "           1       0.59      0.57      0.58       790\n",
      "           2       0.65      0.57      0.61       608\n",
      "           3       0.51      0.41      0.45       684\n",
      "           4       0.58      0.36      0.44       527\n",
      "           5       0.82      0.81      0.82       471\n",
      "\n",
      "    accuracy                           0.61      5070\n",
      "   macro avg       0.62      0.57      0.59      5070\n",
      "weighted avg       0.61      0.61      0.60      5070\n",
      "\n",
      "Epoch 36/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t0.8968 | train acc:\t0.6560\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69      4943\n",
      "           1       0.70      0.57      0.63      2225\n",
      "           2       0.67      0.52      0.59      1539\n",
      "           3       0.61      0.61      0.61      2284\n",
      "           4       0.62      0.53      0.57      1669\n",
      "           5       0.82      0.82      0.82      1298\n",
      "\n",
      "    accuracy                           0.66     13958\n",
      "   macro avg       0.67      0.64      0.65     13958\n",
      "weighted avg       0.66      0.66      0.65     13958\n",
      "\n",
      "test loss:\t1.1278 | test acc:\t0.5905\n",
      "\n",
      "{'val_Other_f1': 0.6322429906542056, 'val_Other_precision': 0.5908296943231441, 'val_Other_recall': 0.6798994974874372, 'val_Saggital_Right_f1': 0.536869340232859, 'val_Saggital_Right_precision': 0.548941798941799, 'val_Saggital_Right_recall': 0.5253164556962026, 'val_Transverse_Right_f1': 0.5487674169346195, 'val_Transverse_Right_precision': 0.7876923076923077, 'val_Transverse_Right_recall': 0.42105263157894735, 'val_Saggital_Left_f1': 0.46766169154228854, 'val_Saggital_Left_precision': 0.45504840940525587, 'val_Saggital_Left_recall': 0.48099415204678364, 'val_Transverse_Left_f1': 0.4886699507389162, 'val_Transverse_Left_precision': 0.5081967213114754, 'val_Transverse_Left_recall': 0.47058823529411764, 'val_Bladder_f1': 0.8196037539103233, 'val_Bladder_precision': 0.805327868852459, 'val_Bladder_recall': 0.8343949044585988, 'test_precision_average_macro': 0.6160061334210735, 'test_recall_average_macro': 0.5687076460936812, 'test_f1score_average_macro': 0.5823025240022021, 'test_precision_average_micro': 0.5905325443786982, 'test_recall_average_micro': 0.5905325443786982, 'test_f1score_average_micro': 0.5905325443786982, 'test_precision_average_weighted': 0.6009298316248227, 'test_recall_average_weighted': 0.5905325443786982, 'test_f1score_average_weighted': 0.5876496940489493, 'test_acc_average': 0.5905325443786982}\n",
      "Epoch 37/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8818 | train acc:\t0.6649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.70      4943\n",
      "           1       0.71      0.57      0.63      2225\n",
      "           2       0.68      0.52      0.59      1539\n",
      "           3       0.60      0.61      0.61      2284\n",
      "           4       0.63      0.56      0.59      1669\n",
      "           5       0.82      0.84      0.83      1298\n",
      "\n",
      "    accuracy                           0.66     13958\n",
      "   macro avg       0.68      0.64      0.66     13958\n",
      "weighted avg       0.67      0.66      0.66     13958\n",
      "\n",
      "test loss:\t1.1099 | test acc:\t0.6012\n",
      "\n",
      "{'val_Other_f1': 0.6385165326184092, 'val_Other_precision': 0.5748189863234111, 'val_Other_recall': 0.7180904522613065, 'val_Saggital_Right_f1': 0.5724585436193224, 'val_Saggital_Right_precision': 0.6649916247906198, 'val_Saggital_Right_recall': 0.5025316455696203, 'val_Transverse_Right_f1': 0.5563451776649746, 'val_Transverse_Right_precision': 0.726790450928382, 'val_Transverse_Right_recall': 0.4506578947368421, 'val_Saggital_Left_f1': 0.4799999999999999, 'val_Saggital_Left_precision': 0.4864864864864865, 'val_Saggital_Left_recall': 0.47368421052631576, 'val_Transverse_Left_f1': 0.4620187304890739, 'val_Transverse_Left_precision': 0.511520737327189, 'val_Transverse_Left_recall': 0.42125237191650855, 'val_Bladder_f1': 0.8195718654434251, 'val_Bladder_precision': 0.788235294117647, 'val_Bladder_recall': 0.8535031847133758, 'test_precision_average_macro': 0.6254739299956226, 'test_recall_average_macro': 0.5699532932873281, 'test_f1score_average_macro': 0.5881518083058676, 'test_precision_average_micro': 0.6011834319526628, 'test_recall_average_micro': 0.6011834319526628, 'test_f1score_average_micro': 0.6011834319526628, 'test_precision_average_weighted': 0.6084238203925505, 'test_recall_average_weighted': 0.6011834319526628, 'test_f1score_average_weighted': 0.5954576404303351, 'test_acc_average': 0.6011834319526628}\n",
      "Epoch 38/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8812 | train acc:\t0.6643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70      4943\n",
      "           1       0.71      0.59      0.64      2225\n",
      "           2       0.69      0.53      0.60      1539\n",
      "           3       0.61      0.60      0.61      2284\n",
      "           4       0.62      0.54      0.58      1669\n",
      "           5       0.83      0.83      0.83      1298\n",
      "\n",
      "    accuracy                           0.66     13958\n",
      "   macro avg       0.68      0.64      0.66     13958\n",
      "weighted avg       0.67      0.66      0.66     13958\n",
      "\n",
      "test loss:\t1.1268 | test acc:\t0.5980\n",
      "\n",
      "{'val_Other_f1': 0.6250629089079014, 'val_Other_precision': 0.626008064516129, 'val_Other_recall': 0.6241206030150753, 'val_Saggital_Right_f1': 0.563092633114515, 'val_Saggital_Right_precision': 0.6643717728055077, 'val_Saggital_Right_recall': 0.48860759493670886, 'val_Transverse_Right_f1': 0.6, 'val_Transverse_Right_precision': 0.6365313653136532, 'val_Transverse_Right_recall': 0.5674342105263158, 'val_Saggital_Left_f1': 0.4884667571234735, 'val_Saggital_Left_precision': 0.45569620253164556, 'val_Saggital_Left_recall': 0.5263157894736842, 'val_Transverse_Left_f1': 0.5008517887563884, 'val_Transverse_Left_precision': 0.45440494590417313, 'val_Transverse_Left_recall': 0.5578747628083491, 'val_Bladder_f1': 0.8124373119358074, 'val_Bladder_precision': 0.7699619771863118, 'val_Bladder_recall': 0.8598726114649682, 'test_precision_average_macro': 0.6011623880429035, 'test_recall_average_macro': 0.6040375953708502, 'test_f1score_average_macro': 0.598318566639681, 'test_precision_average_micro': 0.5980276134122288, 'test_recall_average_micro': 0.5980276134122288, 'test_f1score_average_micro': 0.5980276134122288, 'test_precision_average_weighted': 0.6058068085388653, 'test_recall_average_weighted': 0.5980276134122288, 'test_f1score_average_weighted': 0.5984687371510905, 'test_acc_average': 0.5980276134122288}\n",
      "Epoch 39/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8675 | train acc:\t0.6715\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71      4943\n",
      "           1       0.71      0.59      0.64      2225\n",
      "           2       0.66      0.53      0.59      1539\n",
      "           3       0.61      0.61      0.61      2284\n",
      "           4       0.64      0.57      0.60      1669\n",
      "           5       0.84      0.85      0.85      1298\n",
      "\n",
      "    accuracy                           0.67     13958\n",
      "   macro avg       0.69      0.65      0.67     13958\n",
      "weighted avg       0.67      0.67      0.67     13958\n",
      "\n",
      "test loss:\t1.1183 | test acc:\t0.5953\n",
      "\n",
      "{'val_Other_f1': 0.6452579747377436, 'val_Other_precision': 0.5621036926519956, 'val_Other_recall': 0.757286432160804, 'val_Saggital_Right_f1': 0.5259842519685038, 'val_Saggital_Right_precision': 0.6958333333333333, 'val_Saggital_Right_recall': 0.42278481012658226, 'val_Transverse_Right_f1': 0.5070729053318824, 'val_Transverse_Right_precision': 0.7491961414790996, 'val_Transverse_Right_recall': 0.3832236842105263, 'val_Saggital_Left_f1': 0.4868035190615836, 'val_Saggital_Left_precision': 0.48823529411764705, 'val_Saggital_Left_recall': 0.4853801169590643, 'val_Transverse_Left_f1': 0.47540983606557374, 'val_Transverse_Left_precision': 0.5167037861915368, 'val_Transverse_Left_recall': 0.44022770398481975, 'val_Bladder_f1': 0.8085106382978723, 'val_Bladder_precision': 0.8102345415778252, 'val_Bladder_recall': 0.8067940552016986, 'test_precision_average_macro': 0.637051131558573, 'test_recall_average_macro': 0.5492828004405825, 'test_f1score_average_macro': 0.5748398542438599, 'test_precision_average_micro': 0.5952662721893491, 'test_recall_average_micro': 0.5952662721893491, 'test_f1score_average_micro': 0.5952662721893491, 'test_precision_average_weighted': 0.6137440318170934, 'test_recall_average_weighted': 0.5952662721893491, 'test_f1score_average_weighted': 0.5862355732757377, 'test_acc_average': 0.5952662721893491}\n",
      "Epoch 40/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8610 | train acc:\t0.6715\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71      4943\n",
      "           1       0.72      0.58      0.64      2225\n",
      "           2       0.68      0.55      0.61      1539\n",
      "           3       0.61      0.60      0.61      2284\n",
      "           4       0.64      0.57      0.60      1669\n",
      "           5       0.82      0.84      0.83      1298\n",
      "\n",
      "    accuracy                           0.67     13958\n",
      "   macro avg       0.69      0.65      0.67     13958\n",
      "weighted avg       0.67      0.67      0.67     13958\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:\t1.1222 | test acc:\t0.5974\n",
      "\n",
      "{'val_Other_f1': 0.6236399604352127, 'val_Other_precision': 0.6139240506329114, 'val_Other_recall': 0.6336683417085427, 'val_Saggital_Right_f1': 0.5829652996845426, 'val_Saggital_Right_precision': 0.5811320754716981, 'val_Saggital_Right_recall': 0.5848101265822785, 'val_Transverse_Right_f1': 0.6082289803220036, 'val_Transverse_Right_precision': 0.6666666666666666, 'val_Transverse_Right_recall': 0.5592105263157895, 'val_Saggital_Left_f1': 0.46219081272084805, 'val_Saggital_Left_precision': 0.4473324213406293, 'val_Saggital_Left_recall': 0.4780701754385965, 'val_Transverse_Left_f1': 0.4855721393034826, 'val_Transverse_Left_precision': 0.5104602510460251, 'val_Transverse_Left_recall': 0.4629981024667932, 'val_Bladder_f1': 0.8119218910585817, 'val_Bladder_precision': 0.7868525896414342, 'val_Bladder_recall': 0.8386411889596603, 'test_precision_average_macro': 0.6010613424665608, 'test_recall_average_macro': 0.5928997435786101, 'test_f1score_average_macro': 0.5957531805874452, 'test_precision_average_micro': 0.5974358974358974, 'test_recall_average_micro': 0.5974358974358974, 'test_f1score_average_micro': 0.5974358974358974, 'test_precision_average_weighted': 0.5979747597504594, 'test_recall_average_weighted': 0.5974358974358974, 'test_f1score_average_weighted': 0.5968125388669087, 'test_acc_average': 0.5974358974358974}\n",
      "Epoch 41/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8621 | train acc:\t0.6726\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.71      4943\n",
      "           1       0.71      0.58      0.64      2225\n",
      "           2       0.67      0.53      0.59      1539\n",
      "           3       0.63      0.63      0.63      2284\n",
      "           4       0.64      0.57      0.60      1669\n",
      "           5       0.82      0.83      0.83      1298\n",
      "\n",
      "    accuracy                           0.67     13958\n",
      "   macro avg       0.69      0.65      0.67     13958\n",
      "weighted avg       0.67      0.67      0.67     13958\n",
      "\n",
      "test loss:\t1.1205 | test acc:\t0.6020\n",
      "\n",
      "{'val_Other_f1': 0.6372572524574441, 'val_Other_precision': 0.609353507565337, 'val_Other_recall': 0.6678391959798995, 'val_Saggital_Right_f1': 0.5578135949544499, 'val_Saggital_Right_precision': 0.6248037676609105, 'val_Saggital_Right_recall': 0.5037974683544304, 'val_Transverse_Right_f1': 0.5955882352941176, 'val_Transverse_Right_precision': 0.675, 'val_Transverse_Right_recall': 0.5328947368421053, 'val_Saggital_Left_f1': 0.46612062546537597, 'val_Saggital_Left_precision': 0.47496206373292865, 'val_Saggital_Left_recall': 0.45760233918128657, 'val_Transverse_Left_f1': 0.5004668534080299, 'val_Transverse_Left_precision': 0.49264705882352944, 'val_Transverse_Left_recall': 0.50853889943074, 'val_Bladder_f1': 0.8076923076923077, 'val_Bladder_precision': 0.7381370826010545, 'val_Bladder_recall': 0.89171974522293, 'test_precision_average_macro': 0.6024839133972933, 'test_recall_average_macro': 0.5937320641685653, 'test_f1score_average_macro': 0.5941564782119543, 'test_precision_average_micro': 0.6019723865877712, 'test_recall_average_micro': 0.6019723865877712, 'test_f1score_average_micro': 0.6019723865877712, 'test_precision_average_weighted': 0.6013353203166785, 'test_recall_average_weighted': 0.6019723865877712, 'test_f1score_average_weighted': 0.5984078769133292, 'test_acc_average': 0.6019723865877712}\n",
      "Epoch 42/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8541 | train acc:\t0.6780\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      4943\n",
      "           1       0.72      0.59      0.65      2225\n",
      "           2       0.67      0.56      0.61      1539\n",
      "           3       0.62      0.62      0.62      2284\n",
      "           4       0.64      0.57      0.60      1669\n",
      "           5       0.84      0.84      0.84      1298\n",
      "\n",
      "    accuracy                           0.68     13958\n",
      "   macro avg       0.69      0.66      0.67     13958\n",
      "weighted avg       0.68      0.68      0.68     13958\n",
      "\n",
      "test loss:\t1.1001 | test acc:\t0.5959\n",
      "\n",
      "{'val_Other_f1': 0.627584529311603, 'val_Other_precision': 0.6082036775106082, 'val_Other_recall': 0.6482412060301508, 'val_Saggital_Right_f1': 0.5539906103286385, 'val_Saggital_Right_precision': 0.5891583452211127, 'val_Saggital_Right_recall': 0.5227848101265823, 'val_Transverse_Right_f1': 0.6052393857271906, 'val_Transverse_Right_precision': 0.6713426853707415, 'val_Transverse_Right_recall': 0.5509868421052632, 'val_Saggital_Left_f1': 0.4748982360922659, 'val_Saggital_Left_precision': 0.4430379746835443, 'val_Saggital_Left_recall': 0.5116959064327485, 'val_Transverse_Left_f1': 0.48296593186372744, 'val_Transverse_Left_precision': 0.5116772823779193, 'val_Transverse_Left_recall': 0.4573055028462998, 'val_Bladder_f1': 0.8175182481751825, 'val_Bladder_precision': 0.8032786885245902, 'val_Bladder_recall': 0.832271762208068, 'test_precision_average_macro': 0.6044497756147528, 'test_recall_average_macro': 0.5872143382915187, 'test_f1score_average_macro': 0.593699490249768, 'test_precision_average_micro': 0.5958579881656805, 'test_recall_average_micro': 0.5958579881656805, 'test_f1score_average_micro': 0.5958579881656805, 'test_precision_average_weighted': 0.5986139898358954, 'test_recall_average_weighted': 0.5958579881656805, 'test_f1score_average_weighted': 0.5954508632113711, 'test_acc_average': 0.5958579881656805}\n",
      "Epoch 43/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8415 | train acc:\t0.6849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72      4943\n",
      "           1       0.72      0.60      0.66      2225\n",
      "           2       0.69      0.56      0.62      1539\n",
      "           3       0.64      0.64      0.64      2284\n",
      "           4       0.66      0.58      0.62      1669\n",
      "           5       0.83      0.84      0.84      1298\n",
      "\n",
      "    accuracy                           0.68     13958\n",
      "   macro avg       0.70      0.67      0.68     13958\n",
      "weighted avg       0.69      0.68      0.68     13958\n",
      "\n",
      "test loss:\t1.1003 | test acc:\t0.6008\n",
      "\n",
      "{'val_Other_f1': 0.6423258958755915, 'val_Other_precision': 0.5823457294646506, 'val_Other_recall': 0.7160804020100503, 'val_Saggital_Right_f1': 0.550354609929078, 'val_Saggital_Right_precision': 0.6258064516129033, 'val_Saggital_Right_recall': 0.4911392405063291, 'val_Transverse_Right_f1': 0.5904404873477038, 'val_Transverse_Right_precision': 0.6862745098039216, 'val_Transverse_Right_recall': 0.5180921052631579, 'val_Saggital_Left_f1': 0.464367816091954, 'val_Saggital_Left_precision': 0.48792270531400966, 'val_Saggital_Left_recall': 0.44298245614035087, 'val_Transverse_Left_f1': 0.46056782334384855, 'val_Transverse_Left_precision': 0.5165094339622641, 'val_Transverse_Left_recall': 0.4155597722960152, 'val_Bladder_f1': 0.8164948453608247, 'val_Bladder_precision': 0.7935871743486974, 'val_Bladder_recall': 0.8407643312101911, 'test_precision_average_macro': 0.6154076674177411, 'test_recall_average_macro': 0.5707697179043492, 'test_f1score_average_macro': 0.5874252463248334, 'test_precision_average_micro': 0.6007889546351085, 'test_recall_average_micro': 0.6007889546351085, 'test_f1score_average_micro': 0.6007889546351085, 'test_precision_average_weighted': 0.6016231088009398, 'test_recall_average_weighted': 0.6007889546351085, 'test_f1score_average_weighted': 0.5950517538891233, 'test_acc_average': 0.6007889546351085}\n",
      "Epoch 44/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8400 | train acc:\t0.6785\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      4943\n",
      "           1       0.72      0.60      0.65      2225\n",
      "           2       0.68      0.56      0.61      1539\n",
      "           3       0.63      0.63      0.63      2284\n",
      "           4       0.64      0.57      0.60      1669\n",
      "           5       0.83      0.85      0.84      1298\n",
      "\n",
      "    accuracy                           0.68     13958\n",
      "   macro avg       0.69      0.66      0.67     13958\n",
      "weighted avg       0.68      0.68      0.68     13958\n",
      "\n",
      "test loss:\t1.0981 | test acc:\t0.6022\n",
      "\n",
      "{'val_Other_f1': 0.6455981941309256, 'val_Other_precision': 0.5860655737704918, 'val_Other_recall': 0.7185929648241206, 'val_Saggital_Right_f1': 0.57646229739253, 'val_Saggital_Right_precision': 0.6502384737678856, 'val_Saggital_Right_recall': 0.5177215189873418, 'val_Transverse_Right_f1': 0.5562248995983936, 'val_Transverse_Right_precision': 0.7139175257731959, 'val_Transverse_Right_recall': 0.4555921052631579, 'val_Saggital_Left_f1': 0.4774980930587338, 'val_Saggital_Left_precision': 0.49920255183413076, 'val_Saggital_Left_recall': 0.45760233918128657, 'val_Transverse_Left_f1': 0.4912280701754386, 'val_Transverse_Left_precision': 0.4784172661870504, 'val_Transverse_Left_recall': 0.5047438330170778, 'val_Bladder_f1': 0.7946725860155384, 'val_Bladder_precision': 0.8325581395348837, 'val_Bladder_recall': 0.7600849256900213, 'test_precision_average_macro': 0.6267332551446064, 'test_recall_average_macro': 0.569056281160501, 'test_f1score_average_macro': 0.5902806900619266, 'test_precision_average_micro': 0.6021696252465484, 'test_recall_average_micro': 0.6021696252465484, 'test_f1score_average_micro': 0.6021696252465484, 'test_precision_average_weighted': 0.6113877850505055, 'test_recall_average_weighted': 0.6021696252465484, 'test_f1score_average_weighted': 0.5992321571724679, 'test_acc_average': 0.6021696252465484}\n",
      "Epoch 45/46\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:\t0.8336 | train acc:\t0.6792\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      4943\n",
      "           1       0.71      0.60      0.65      2225\n",
      "           2       0.69      0.56      0.62      1539\n",
      "           3       0.63      0.62      0.63      2284\n",
      "           4       0.64      0.57      0.61      1669\n",
      "           5       0.84      0.84      0.84      1298\n",
      "\n",
      "    accuracy                           0.68     13958\n",
      "   macro avg       0.70      0.66      0.68     13958\n",
      "weighted avg       0.68      0.68      0.68     13958\n",
      "\n",
      "test loss:\t1.0883 | test acc:\t0.6024\n",
      "\n",
      "{'val_Other_f1': 0.6444035006909259, 'val_Other_precision': 0.594812925170068, 'val_Other_recall': 0.7030150753768845, 'val_Saggital_Right_f1': 0.5617647058823529, 'val_Saggital_Right_precision': 0.6701754385964912, 'val_Saggital_Right_recall': 0.4835443037974684, 'val_Transverse_Right_f1': 0.5466377440347072, 'val_Transverse_Right_precision': 0.802547770700637, 'val_Transverse_Right_recall': 0.4144736842105263, 'val_Saggital_Left_f1': 0.5, 'val_Saggital_Left_precision': 0.4738219895287958, 'val_Saggital_Left_recall': 0.5292397660818714, 'val_Transverse_Left_f1': 0.4830741079597438, 'val_Transverse_Left_precision': 0.4664310954063604, 'val_Transverse_Left_recall': 0.5009487666034156, 'val_Bladder_f1': 0.8102564102564104, 'val_Bladder_precision': 0.7837301587301587, 'val_Bladder_recall': 0.8386411889596603, 'test_precision_average_macro': 0.6319198963554185, 'test_recall_average_macro': 0.5783104641716378, 'test_f1score_average_macro': 0.5910227448040234, 'test_precision_average_micro': 0.6023668639053255, 'test_recall_average_micro': 0.6023668639053255, 'test_f1score_average_micro': 0.6023668639053255, 'test_precision_average_weighted': 0.6193502357089553, 'test_recall_average_weighted': 0.6023668639053255, 'test_f1score_average_weighted': 0.5989593010888871, 'test_acc_average': 0.6023668639053255}\n",
      "Epoch 46/46\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8232 | train acc:\t0.6884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.78      0.72      4943\n",
      "           1       0.71      0.60      0.65      2225\n",
      "           2       0.71      0.58      0.64      1539\n",
      "           3       0.63      0.63      0.63      2284\n",
      "           4       0.66      0.59      0.62      1669\n",
      "           5       0.85      0.85      0.85      1298\n",
      "\n",
      "    accuracy                           0.69     13958\n",
      "   macro avg       0.70      0.67      0.69     13958\n",
      "weighted avg       0.69      0.69      0.69     13958\n",
      "\n",
      "test loss:\t1.1471 | test acc:\t0.5864\n",
      "\n",
      "{'val_Other_f1': 0.6101960784313724, 'val_Other_precision': 0.635967302452316, 'val_Other_recall': 0.58643216080402, 'val_Saggital_Right_f1': 0.5539057456423498, 'val_Saggital_Right_precision': 0.5652173913043478, 'val_Saggital_Right_recall': 0.5430379746835443, 'val_Transverse_Right_f1': 0.6018596787827558, 'val_Transverse_Right_precision': 0.6191304347826087, 'val_Transverse_Right_recall': 0.5855263157894737, 'val_Saggital_Left_f1': 0.47361963190184053, 'val_Saggital_Left_precision': 0.4080338266384778, 'val_Saggital_Left_recall': 0.564327485380117, 'val_Transverse_Left_f1': 0.4855967078189301, 'val_Transverse_Left_precision': 0.5303370786516854, 'val_Transverse_Left_recall': 0.4478178368121442, 'val_Bladder_f1': 0.8134556574923548, 'val_Bladder_precision': 0.7823529411764706, 'val_Bladder_recall': 0.8471337579617835, 'test_precision_average_macro': 0.5901731625009844, 'test_recall_average_macro': 0.5957125885718472, 'test_f1score_average_macro': 0.5897722500116006, 'test_precision_average_micro': 0.5863905325443787, 'test_recall_average_micro': 0.5863905325443787, 'test_f1score_average_micro': 0.5863905325443787, 'test_precision_average_weighted': 0.594792699905847, 'test_recall_average_weighted': 0.5863905325443787, 'test_f1score_average_weighted': 0.5879308338769502, 'test_acc_average': 0.5863905325443787}\n",
      "Training complete in 22m 37s\n",
      "Best val acc: 0.605720\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denizjafari/hnultra\" target=\"_blank\">https://app.wandb.ai/denizjafari/hnultra</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denizjafari/hnultra/runs/276ckza0\" target=\"_blank\">https://app.wandb.ai/denizjafari/hnultra/runs/276ckza0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7eb04fec5f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                   'conv3_filters': conv3_filters, 'linear1_size': linear1_size }\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain5fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion_used\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-432041f82f7f>\u001b[0m in \u001b[0;36mtrain5fold\u001b[0;34m(network_configs, criterion_used, model_ft, lr, wd, amsgrad, i)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Calculate the performance metrics on the best model in each fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hnultra'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb_username\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_username\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ALL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fold'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, name, notes, id, magic, anonymous, config_exclude_keys, config_include_keys)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mallow_val_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtelemetry_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         run.config._update(config,\n\u001b[0m\u001b[1;32m   1110\u001b[0m                 \u001b[0mexclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_exclude_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 \u001b[0minclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_include_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/wandb_config.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, params, allow_val_change, as_defaults, exclude_keys, include_keys)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_val_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/wandb_config.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mconf_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"dryrun\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_stream_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirror_stdout_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, run, project, tags, cloud, output, port)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# Calling .start() on _meta and _system_stats will spin a thread that reports system stats every 30 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSystemStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jobType\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/meta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api, out_dir)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/meta.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Windows\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SIGALRM'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0min_jupyter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"non time limited probe of code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_code_git\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_code_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/meta.py\u001b[0m in \u001b[0;36m_setup_code_git\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m             }\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_code_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/wandb/git_repo.py\u001b[0m in \u001b[0;36mroot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrev_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--show-toplevel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/git/cmd.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_persistent_git_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/git/cmd.py\u001b[0m in \u001b[0;36m_call_process\u001b[0;34m(self, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexec_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_object_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/site-packages/git/cmd.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, istream, with_extended_output, with_exceptions, as_process, output_stream, stdout_as_string, kill_after_timeout, with_stdout, universal_newlines, shell, env, max_chunk_size, **subprocess_kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m                   command, cwd, universal_newlines, shell, istream_ok)\n\u001b[1;32m    720\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             proc = Popen(command,\n\u001b[0m\u001b[1;32m    722\u001b[0m                          \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                          \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hnu/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1635\u001b[0m                     \u001b[0mfds_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_fds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m                     \u001b[0mfds_to_keep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m                     self.pid = _posixsubprocess.fork_exec(\n\u001b[0m\u001b[1;32m   1638\u001b[0m                             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutable_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                             \u001b[0mclose_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfds_to_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "repetitions = 5\n",
    "\n",
    "conv1_filters = 8\n",
    "conv2_filters = 16\n",
    "conv3_filters = 32\n",
    "linear1_size = 512\n",
    "\n",
    "dropout = 0.25\n",
    "lr = 0.0005\n",
    "wd = 0.001\n",
    "amsgrad = False\n",
    "\n",
    "for i in range(repetitions):\n",
    "    config_string = f\"{conv1_filters}_{conv2_filters}_{conv3_filters}_{linear1_size}_{dropout}_{lr}_{wd}_{amsgrad}\"\n",
    "    model_ft = ViewNet(num_classes, conv1_filters, conv2_filters, conv3_filters, linear1_size, dropout)\n",
    "    run_configs = {'lr': lr, 'wd': wd, 'amsgrad': amsgrad,'dropout': dropout, \n",
    "                  'conv1_filters': conv1_filters, 'conv2_filters': conv2_filters, \n",
    "                  'conv3_filters': conv3_filters, 'linear1_size': linear1_size }\n",
    "\n",
    "    train5fold(run_configs,criterion_used, model_ft, lr, wd, amsgrad, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "image_label.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
