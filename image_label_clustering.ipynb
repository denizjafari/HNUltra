{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZbZRovgc-In"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from torch.utils import data\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import io\n",
    "import uuid\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import wandb\n",
    "#wandb_username = 'denizjafari'\n",
    "local_username = 'denizjafari'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2aVSXNyc-Iv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylfRtoN9c-Iy"
   },
   "outputs": [],
   "source": [
    "# root directory\n",
    "root_dir = \"/home/andreasabo/Documents/HNProject/\"\n",
    "split_file_base = \"/home/denizjafari/Documents/HNProject/HNUltra/\"\n",
    "\n",
    "# data directory on current machine: abhishekmoturu, andreasabo, denizjafari, navidkorhani\n",
    "data_dir = \"/home/\" + local_username + \"/Documents/HNProject/all_label_img/\"\n",
    "\n",
    "# read target df\n",
    "csv_path = os.path.join(root_dir, \"all_splits_1000000.csv\")\n",
    "data_df = pd.read_csv(csv_path, usecols=['subj_id', 'image_ids', 'view_label', 'view_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_ids</th>\n",
       "      <th>view_label</th>\n",
       "      <th>subj_id</th>\n",
       "      <th>view_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323_2_1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1323_2_2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1323_2_3</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1323_2_4</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323_2_5</td>\n",
       "      <td>Missing</td>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_ids view_label  subj_id  view_train\n",
       "0  1323_2_1    Missing     1323         NaN\n",
       "1  1323_2_2    Missing     1323         NaN\n",
       "2  1323_2_3    Missing     1323         NaN\n",
       "3  1323_2_4    Missing     1323         NaN\n",
       "4  1323_2_5    Missing     1323         NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_OCR_7uy52w"
   },
   "source": [
    "### **Reading Data Indicies and Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'Other':0, 'Saggital_Right':1, 'Transverse_Right':2, \n",
    "                 'Saggital_Left':3, 'Transverse_Left':4, 'Bladder':5}\n",
    "\n",
    "data_df['view_label'] = data_df['view_label'].map(label_mapping)\n",
    "\n",
    "train_df = data_df[data_df.view_train == 1]\n",
    "test_df = data_df[data_df.view_train == 0]\n",
    "\n",
    "labels = {}\n",
    "train_and_valid_subj_ids = []\n",
    "train_and_valid_image_ids = []\n",
    "test_ids = []\n",
    "\n",
    "for ind, row in train_df.iterrows():\n",
    "    train_and_valid_subj_ids.append(row['subj_id'])\n",
    "    train_and_valid_image_ids.append(row['image_ids'])\n",
    "    labels[row['image_ids']] = row['view_label']\n",
    "\n",
    "for ind, row in test_df.iterrows():\n",
    "    test_ids.append(row['image_ids'])\n",
    "    labels[row['image_ids']] = row['view_label']\n",
    "\n",
    "s = set()\n",
    "t_v_ids = pd.DataFrame(list(zip(train_and_valid_subj_ids, train_and_valid_image_ids)), columns=['subj_ids', 'image_ids'])\n",
    "id_groups = [t_v_ids for _, t_v_ids in t_v_ids.groupby('subj_ids')]\n",
    "random.shuffle(id_groups)\n",
    "id_groups = pd.concat(id_groups).reset_index(drop=True)\n",
    "train_val_split = int(0.8*len(set(id_groups['subj_ids'].values)))\n",
    "train_val_set = [i for i in id_groups['subj_ids'].values if not (i in s or s.add(i))]\n",
    "cutoff = train_val_set[train_val_split]\n",
    "train_portion = (id_groups['subj_ids'].values == cutoff).argmax()\n",
    "\n",
    "train_ids = id_groups[:train_portion]['image_ids'].tolist()\n",
    "valid_ids = id_groups[train_portion:]['image_ids'].tolist()\n",
    "\n",
    "partition = {'train':train_ids, 'valid':valid_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nnwavxcqGBv"
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "\n",
    "    label_mapping = {'Other':0, 'Saggital_Right':1, 'Transverse_Right':2, \n",
    "                     'Saggital_Left':3, 'Transverse_Left':4, 'Bladder':5}\n",
    "    label_unmapping = {0: 'Other', 1:'Saggital_Right', 2: 'Transverse_Right', \n",
    "                       3:'Saggital_Left', 4:'Transverse_Left', 5: 'Bladder'}\n",
    "\n",
    "    data_df['view_label'] = data_df['view_label'].map(label_mapping)\n",
    "\n",
    "    train_df = data_df[data_df.view_train == 1]\n",
    "    test_df = data_df[data_df.view_train == 0]\n",
    "\n",
    "    unique_subj = train_df.subj_id.unique()\n",
    "\n",
    "    # Create the splits for 5-fold cross validation based on subj_id\n",
    "    data_split_file = split_file_base + 'data_splits.json'\n",
    "    if not os.path.isfile(data_split_file):\n",
    "\n",
    "        kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "        fold = 0\n",
    "        all_folds = {}\n",
    "        for train_subj, val_subj in kf.split(unique_subj):\n",
    "            train_ids  = unique_subj[train_subj]\n",
    "            val_ids = unique_subj[val_subj]\n",
    "\n",
    "            train_images = train_df[train_df.subj_id.isin(train_ids)].image_ids.tolist()\n",
    "            val_images = train_df[train_df.subj_id.isin(val_ids)].image_ids.tolist()\n",
    "            train_labels = train_df[train_df.subj_id.isin(train_ids)].view_label.tolist()\n",
    "            val_labels = train_df[train_df.subj_id.isin(val_ids)].view_label.tolist()\n",
    "            cur_fold = {'train_ids': train_images, 'valid_ids': val_images, 'train_labels': train_labels, 'valid_labels': val_labels}\n",
    "            all_folds[fold] = cur_fold\n",
    "            fold += 1\n",
    "\n",
    "        print(\"Saving data splits\")\n",
    "        with open(data_split_file, 'w') as f:\n",
    "            json.dump(all_folds, f)\n",
    "\n",
    "    else: # just load from file\n",
    "        print(\"Reading splits from file\")\n",
    "        with open(data_split_file, 'r') as f:\n",
    "            all_folds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbgEWoqKc-JO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    elif model_name == 'viewnet':\n",
    "        conv1_filters = 8\n",
    "        conv2_filters = 16\n",
    "        conv3_filters = 32\n",
    "        linear1_size = 512\n",
    "        dropout = 0.25\n",
    "        model_ft = ViewNet(num_classes, conv1_filters, conv2_filters, conv3_filters, linear1_size, dropout)\n",
    "        input_size = 256\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False, writer = None):\n",
    "    since = time.time()\n",
    "    classnames = ['Other', 'Saggital_Right', 'Transverse_Right', 'Saggital_Left','Transverse_Left', 'Bladder']\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 54)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            running_preds = []\n",
    "            running_labels = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.type(torch.long)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        labels = torch.argmax(labels, 1)\n",
    "                        running_preds += torch.argmax(outputs, 1).tolist()\n",
    "                        running_labels += labels.tolist()\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} loss:\\t{:.4f} | {} acc:\\t{:.4f}\\n'.format(phase, epoch_loss, phase, epoch_acc))\n",
    "            # Log to tensorboard for visualization\n",
    "            if writer is not None and phase == 'train':\n",
    "                writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "#                 cm = confusion_matrix(running_labels, running_preds)\n",
    "#                 figure = plot_confusion_matrix_local(cm, classnames)\n",
    "#                 writer.add_image('confusion_matrix/train', figure, epoch)\n",
    "                \n",
    "                \n",
    "                \n",
    "            if writer is not None and phase == 'val':\n",
    "                writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/val', epoch_acc, epoch)\n",
    "                \n",
    "#                 cm = confusion_matrix(running_labels, running_preds)\n",
    "#                 figure = plot_confusion_matrix_local(cm, classnames)\n",
    "#                 writer.add_image('confusion_matrix/val', figure, epoch)\n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                print(classification_report(running_labels, running_preds))\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(classification_report(running_labels, running_preds))\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "        since = time.time()\n",
    "        classnames = ['Other', 'Saggital_Right', 'Transverse_Right', 'Saggital_Left','Transverse_Left', 'Bladder']\n",
    "        val_acc_history = []\n",
    "\n",
    "        val_metrics_list = []\n",
    "        train_metrics_list = []\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_acc = 0.0\n",
    "        epoch_with_best_val_acc = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "            print('-' * 54)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                running_preds = []\n",
    "                running_labels = []\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    labels = labels.type(torch.long)\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # Get model outputs and calculate loss\n",
    "                        # Special case for inception because in training it has an auxiliary output. In train\n",
    "                        #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                        #   but in testing we only consider the final output.\n",
    "                        if is_inception and phase == 'train':\n",
    "                            # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                            outputs, aux_outputs = model(inputs)\n",
    "                            loss1 = criterion(outputs, labels)\n",
    "                            loss2 = criterion(aux_outputs, labels)\n",
    "                            loss = loss1 + 0.4*loss2\n",
    "                        else:\n",
    "                            outputs = model(inputs)\n",
    "                            labels = torch.argmax(labels, 1)\n",
    "                            running_preds += torch.argmax(outputs, 1).tolist()\n",
    "                            running_labels += labels.tolist()\n",
    "                            loss = criterion(outputs, labels)\n",
    "\n",
    "                        preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "                print('{} loss:\\t{:.4f} | {} acc:\\t{:.4f}\\n'.format(phase, epoch_loss, phase, epoch_acc))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    wandb.log({'epoch': epoch, 'train_loss':epoch_loss})\n",
    "                    wandb.log({'epoch': epoch, 'train_acc':epoch_acc})\n",
    "\n",
    "                    cur_train_metrics = {}\n",
    "                                    # compute and log f1, precision, recall for each class\n",
    "                    for c in range(6):\n",
    "                        running_labels = np.asarray(running_labels)\n",
    "                        running_preds = np.asarray(running_preds)\n",
    "\n",
    "                        cur_c_labs_bin = np.asarray([0] *len(running_labels))\n",
    "                        cur_c_preds_bin = np.asarray([0] *len(running_labels))\n",
    "\n",
    "                        # Need to binarize\n",
    "                        cur_c_preds_bin[running_preds == c] = 1\n",
    "                        cur_c_labs_bin[running_labels == c] = 1\n",
    "                        f1 = f1_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                        precision = precision_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                        recall = recall_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "\n",
    "                        cur_train_metrics['train_' + label_unmapping[c] + '_f1'] = f1\n",
    "                        cur_train_metrics['train_' + label_unmapping[c] + '_precision'] = precision\n",
    "                        cur_train_metrics['train_' + label_unmapping[c] + '_recall'] = recall\n",
    "\n",
    "\n",
    "                    train_metrics_list.append(cur_train_metrics)\n",
    "\n",
    "\n",
    "\n",
    "                if phase == 'val':\n",
    "                    wandb.log({'epoch': epoch, 'valid_loss':epoch_loss})\n",
    "                    wandb.log({'epoch': epoch, 'valid_acc':epoch_acc})\n",
    "\n",
    "\n",
    "                    cur_val_metrics = {}\n",
    "                    # compute and log f1, precision, recall for each class\n",
    "                    for c in range(6):\n",
    "                        running_labels = np.asarray(running_labels)\n",
    "                        running_preds = np.asarray(running_preds)\n",
    "\n",
    "                        cur_c_labs_bin = np.asarray([0] *len(running_labels))\n",
    "                        cur_c_preds_bin = np.asarray([0] *len(running_labels))\n",
    "\n",
    "                        # Need to binarize\n",
    "                        cur_c_preds_bin[running_preds == c] = 1\n",
    "                        cur_c_labs_bin[running_labels == c] = 1\n",
    "                        f1 = f1_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                        precision = precision_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                        recall = recall_score(cur_c_labs_bin, cur_c_preds_bin)\n",
    "                        wandb.log({'epoch': epoch, 'valid_' + label_unmapping[c] + '_f1': f1})\n",
    "                        wandb.log({'epoch': epoch, 'valid_' + label_unmapping[c] + '_precision': precision})\n",
    "                        wandb.log({'epoch': epoch, 'valid_' + label_unmapping[c] + '_recall': recall})\n",
    "\n",
    "                        cur_val_metrics['val_' + label_unmapping[c] + '_f1'] = f1\n",
    "                        cur_val_metrics['val_' + label_unmapping[c] + '_precision'] = precision\n",
    "                        cur_val_metrics['val_' + label_unmapping[c] + '_recall'] = recall\n",
    "\n",
    "                    val_metrics_list.append(cur_val_metrics)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    print(classification_report(running_labels, running_preds))\n",
    "                    train_acc = epoch_acc\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_acc_train = train_acc\n",
    "                    epoch_with_best_val_acc = epoch\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model.state_dict(), os.path.join(wandb.run.dir, \"model.pt\"))\n",
    "                    print(classification_report(running_labels, running_preds))\n",
    "                if phase == 'val':\n",
    "                    val_acc_history.append(epoch_acc)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val acc: {:4f}\\n'.format(best_acc))\n",
    "\n",
    "        # Directly save the best results in this fold\n",
    "        wandb.config.best_acc = best_acc\n",
    "        wandb.config.val_acc_history = val_acc_history\n",
    "        wandb.config.best_epoch = epoch_with_best_val_acc\n",
    "\n",
    "        wandb.config.update(val_metrics_list[epoch_with_best_val_acc])\n",
    "        wandb.config.update(train_metrics_list[epoch_with_best_val_acc])\n",
    "\n",
    "        metrics_from_best_epoch = {'best_epoch': epoch_with_best_val_acc}\n",
    "        metrics_from_best_epoch.update( val_metrics_list[epoch_with_best_val_acc] )\n",
    "        metrics_from_best_epoch.update( train_metrics_list[epoch_with_best_val_acc] )\n",
    "        metrics_from_best_epoch.update( {'val_acc': best_acc, 'train_acc': best_acc_train} )    \n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        return model, val_acc_history, metrics_from_best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iikM7_G3c-JR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception, viewnet]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset: right_sag, right_trav, left_sag, left_trav, bladder, other\n",
    "num_classes = 6\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 100\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 200\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model; when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "\n",
    "# Flag for whether or not to use pretrained model\n",
    "pretrain = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True)\n",
    "#print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=1e-5, weight_decay=0, amsgrad=True) # lr=1e-4, weight_decay=0, amsgrad=False\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        img_path = data_dir + ID + '.jpg'\n",
    "        image = Image.open(img_path)#.convert('L')\n",
    "        image = ToTensor()(image)\n",
    "        y = torch.FloatTensor([0]*6)\n",
    "       \n",
    "        y[int(self.labels[ID])] = 1\n",
    "\n",
    "        return image, y\n",
    "# Parameters\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['valid'], labels)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "dataloaders_dict = {'train':training_generator, 'val':validation_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3335\n",
      "3335\n"
     ]
    }
   ],
   "source": [
    "partition['valid']\n",
    "labels\n",
    "y_val = [labels[key] for key in partition['valid']]\n",
    "\n",
    "print(len(partition['valid']))\n",
    "print(len(y_val))\n",
    "#y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "------------------------------------------------------\n",
      "train loss:\t1.5930 | train acc:\t0.3623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.30      0.42      3725\n",
      "           1       0.35      0.35      0.35      1649\n",
      "           2       0.22      0.05      0.08      1184\n",
      "           3       0.33      0.37      0.35      1741\n",
      "           4       0.21      0.61      0.31      1334\n",
      "           5       0.53      0.65      0.58       990\n",
      "\n",
      "    accuracy                           0.36     10623\n",
      "   macro avg       0.39      0.39      0.35     10623\n",
      "weighted avg       0.45      0.36      0.36     10623\n",
      "\n",
      "val loss:\t1.4248 | val acc:\t0.4717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.55      1218\n",
      "           1       0.47      0.47      0.47       576\n",
      "           2       0.35      0.18      0.24       355\n",
      "           3       0.38      0.41      0.40       543\n",
      "           4       0.23      0.43      0.30       335\n",
      "           5       0.70      0.83      0.76       308\n",
      "\n",
      "    accuracy                           0.47      3335\n",
      "   macro avg       0.46      0.47      0.45      3335\n",
      "weighted avg       0.49      0.47      0.47      3335\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------------------------------\n",
      "train loss:\t1.1610 | train acc:\t0.5906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68      3725\n",
      "           1       0.57      0.52      0.55      1649\n",
      "           2       0.60      0.25      0.35      1184\n",
      "           3       0.51      0.55      0.53      1741\n",
      "           4       0.43      0.54      0.48      1334\n",
      "           5       0.71      0.84      0.77       990\n",
      "\n",
      "    accuracy                           0.59     10623\n",
      "   macro avg       0.58      0.57      0.56     10623\n",
      "weighted avg       0.59      0.59      0.58     10623\n",
      "\n",
      "val loss:\t1.2068 | val acc:\t0.5496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63      1218\n",
      "           1       0.62      0.46      0.53       576\n",
      "           2       0.47      0.25      0.33       355\n",
      "           3       0.46      0.41      0.44       543\n",
      "           4       0.35      0.34      0.34       335\n",
      "           5       0.76      0.85      0.80       308\n",
      "\n",
      "    accuracy                           0.55      3335\n",
      "   macro avg       0.54      0.51      0.51      3335\n",
      "weighted avg       0.54      0.55      0.54      3335\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.9705 | train acc:\t0.6670\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      3725\n",
      "           1       0.69      0.55      0.62      1649\n",
      "           2       0.68      0.46      0.55      1184\n",
      "           3       0.59      0.64      0.62      1741\n",
      "           4       0.59      0.55      0.57      1334\n",
      "           5       0.79      0.85      0.82       990\n",
      "\n",
      "    accuracy                           0.67     10623\n",
      "   macro avg       0.67      0.64      0.65     10623\n",
      "weighted avg       0.67      0.67      0.66     10623\n",
      "\n",
      "val loss:\t1.1494 | val acc:\t0.5742\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65      1218\n",
      "           1       0.68      0.46      0.55       576\n",
      "           2       0.48      0.39      0.43       355\n",
      "           3       0.50      0.42      0.46       543\n",
      "           4       0.38      0.41      0.39       335\n",
      "           5       0.77      0.87      0.82       308\n",
      "\n",
      "    accuracy                           0.57      3335\n",
      "   macro avg       0.57      0.55      0.55      3335\n",
      "weighted avg       0.57      0.57      0.57      3335\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.8416 | train acc:\t0.7144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      3725\n",
      "           1       0.76      0.60      0.67      1649\n",
      "           2       0.74      0.52      0.61      1184\n",
      "           3       0.66      0.69      0.67      1741\n",
      "           4       0.67      0.62      0.64      1334\n",
      "           5       0.84      0.86      0.85       990\n",
      "\n",
      "    accuracy                           0.71     10623\n",
      "   macro avg       0.73      0.69      0.70     10623\n",
      "weighted avg       0.72      0.71      0.71     10623\n",
      "\n",
      "val loss:\t1.0991 | val acc:\t0.5904\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.66      1218\n",
      "           1       0.68      0.51      0.58       576\n",
      "           2       0.52      0.41      0.45       355\n",
      "           3       0.52      0.43      0.47       543\n",
      "           4       0.42      0.42      0.42       335\n",
      "           5       0.79      0.86      0.82       308\n",
      "\n",
      "    accuracy                           0.59      3335\n",
      "   macro avg       0.59      0.56      0.57      3335\n",
      "weighted avg       0.59      0.59      0.58      3335\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.7392 | train acc:\t0.7560\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      3725\n",
      "           1       0.80      0.64      0.71      1649\n",
      "           2       0.80      0.60      0.68      1184\n",
      "           3       0.72      0.73      0.72      1741\n",
      "           4       0.72      0.69      0.70      1334\n",
      "           5       0.87      0.88      0.87       990\n",
      "\n",
      "    accuracy                           0.76     10623\n",
      "   macro avg       0.77      0.73      0.75     10623\n",
      "weighted avg       0.76      0.76      0.75     10623\n",
      "\n",
      "val loss:\t1.0809 | val acc:\t0.5961\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      1218\n",
      "           1       0.68      0.54      0.60       576\n",
      "           2       0.52      0.43      0.47       355\n",
      "           3       0.52      0.41      0.46       543\n",
      "           4       0.45      0.42      0.43       335\n",
      "           5       0.80      0.85      0.83       308\n",
      "\n",
      "    accuracy                           0.60      3335\n",
      "   macro avg       0.59      0.56      0.57      3335\n",
      "weighted avg       0.59      0.60      0.59      3335\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.6430 | train acc:\t0.7978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      3725\n",
      "           1       0.84      0.70      0.76      1649\n",
      "           2       0.83      0.68      0.75      1184\n",
      "           3       0.77      0.78      0.78      1741\n",
      "           4       0.79      0.73      0.76      1334\n",
      "           5       0.90      0.89      0.90       990\n",
      "\n",
      "    accuracy                           0.80     10623\n",
      "   macro avg       0.82      0.78      0.79     10623\n",
      "weighted avg       0.80      0.80      0.80     10623\n",
      "\n",
      "val loss:\t1.0713 | val acc:\t0.6051\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66      1218\n",
      "           1       0.67      0.55      0.61       576\n",
      "           2       0.54      0.46      0.50       355\n",
      "           3       0.53      0.47      0.50       543\n",
      "           4       0.45      0.45      0.45       335\n",
      "           5       0.81      0.86      0.83       308\n",
      "\n",
      "    accuracy                           0.61      3335\n",
      "   macro avg       0.60      0.58      0.59      3335\n",
      "weighted avg       0.60      0.61      0.60      3335\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.5487 | train acc:\t0.8371\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86      3725\n",
      "           1       0.88      0.75      0.81      1649\n",
      "           2       0.88      0.72      0.79      1184\n",
      "           3       0.83      0.83      0.83      1741\n",
      "           4       0.82      0.78      0.80      1334\n",
      "           5       0.93      0.90      0.91       990\n",
      "\n",
      "    accuracy                           0.84     10623\n",
      "   macro avg       0.86      0.82      0.83     10623\n",
      "weighted avg       0.84      0.84      0.84     10623\n",
      "\n",
      "val loss:\t1.0721 | val acc:\t0.6027\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.4597 | train acc:\t0.8775\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      3725\n",
      "           1       0.90      0.81      0.85      1649\n",
      "           2       0.90      0.79      0.84      1184\n",
      "           3       0.89      0.87      0.88      1741\n",
      "           4       0.87      0.84      0.85      1334\n",
      "           5       0.94      0.92      0.93       990\n",
      "\n",
      "    accuracy                           0.88     10623\n",
      "   macro avg       0.89      0.86      0.88     10623\n",
      "weighted avg       0.88      0.88      0.88     10623\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss:\t1.0817 | val acc:\t0.5991\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.3823 | train acc:\t0.9103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      3725\n",
      "           1       0.94      0.85      0.89      1649\n",
      "           2       0.94      0.84      0.89      1184\n",
      "           3       0.92      0.92      0.92      1741\n",
      "           4       0.91      0.87      0.89      1334\n",
      "           5       0.95      0.94      0.95       990\n",
      "\n",
      "    accuracy                           0.91     10623\n",
      "   macro avg       0.92      0.90      0.91     10623\n",
      "weighted avg       0.91      0.91      0.91     10623\n",
      "\n",
      "val loss:\t1.0892 | val acc:\t0.6006\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------------------------------\n",
      "train loss:\t0.3090 | train acc:\t0.9378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      3725\n",
      "           1       0.95      0.89      0.92      1649\n",
      "           2       0.95      0.89      0.92      1184\n",
      "           3       0.96      0.95      0.95      1741\n",
      "           4       0.94      0.90      0.92      1334\n",
      "           5       0.97      0.95      0.96       990\n",
      "\n",
      "    accuracy                           0.94     10623\n",
      "   macro avg       0.95      0.93      0.94     10623\n",
      "weighted avg       0.94      0.94      0.94     10623\n",
      "\n",
      "val loss:\t1.1078 | val acc:\t0.6015\n",
      "\n",
      "Training complete in 4m 18s\n",
      "Best val acc: 0.605097\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, 10, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "class I(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(I, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "model = model_ft\n",
    "model = model.to(device)\n",
    "model.fc = I()\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['valid'], labels)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "dataloaders = {'train':training_generator, 'val':validation_generator}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3335\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = []\n",
    "label_predictions = []\n",
    "for image, label in dataloaders['val']:\n",
    "    features.append(np.squeeze(model(image.to(device)).tolist()))\n",
    "    label_predictions.append(torch.argmax(label, 1)[0].item())\n",
    "    \n",
    "#features = np.asarray(features)\n",
    "#labels = np.asarray(labels)\n",
    "print(len(features))\n",
    "print(features[-1].shape)\n",
    "#for i in features:\n",
    "#    print(i.shape)\n",
    "#features.remove(features[-1])\n",
    "#labels.remove(labels[-1] )  \n",
    "#print(features[-1].shape)\n",
    "#print(len(features))\n",
    "kmeans = KMeans(n_clusters=6, random_state=0).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003319331662646694\n"
     ]
    }
   ],
   "source": [
    "print(v_measure_score(y_val, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "3335\n",
      "19028\n"
     ]
    }
   ],
   "source": [
    "#print(v_measure_score(labels, kmeans.labels_))\n",
    "print(features[0].shape)\n",
    "print(len(label_predictions))\n",
    "print(len(labels))\n",
    "#print(label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot tsne clustering based on conv layer outputs, with labels of correct answer\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla() # Clear current axis\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()) \n",
    "    plt.ylim(Y.min(), Y.max())\n",
    "    plt.show()\n",
    "\n",
    "tsne = TSNE(perplexity=50, n_components=2, init='pca', n_iter=10000)\n",
    "low_dim_embs = tsne.fit_transform(features)\n",
    "#plot_with_labels(low_dim_embs, label_predictions)\n",
    "plot_with_labels(low_dim_embs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_with_labels(low_dim_embs, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-978db5a49ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'g.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'olive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mXk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "X= features\n",
    "\n",
    "clust = OPTICS(min_samples=50, xi=.05, min_cluster_size=.05)\n",
    "\n",
    "clust.fit(X)\n",
    "space = np.arange(len(X))\n",
    "reachability = clust.reachability_[clust.ordering_]\n",
    "optics_labels = clust.labels_[clust.ordering_]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# OPTICS\n",
    "colors = ['g.', 'r.', 'b.', 'olive','y.', 'c.']\n",
    "for klass, color in zip(range(0, 6), colors):\n",
    "    Xk = X[clust.labels_ == klass]\n",
    "    ax.plot(Xk[:, 0], Xk[:, 1], color, alpha=0.3)\n",
    "ax.plot(X[clust.labels_ == -1, 0], X[clust.labels_ == -1, 1], 'k+', alpha=0.1)\n",
    "ax.set_title('Automatic Clustering\\nOPTICS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optics_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3335\n",
      "[1.47380710e+00 8.66795421e-01 3.85018110e-01 1.54473889e+00\n",
      " 3.90727013e-01 3.48594129e-01 4.11847740e-01 1.18814421e+00\n",
      " 1.89476323e+00 1.03700209e+00 3.19195598e-01 4.85074699e-01\n",
      " 6.66504502e-01 1.19207048e+00 8.93867254e-01 1.21533418e+00\n",
      " 1.18426085e-01 5.38526058e-01 7.49503374e-01 1.43154860e-01\n",
      " 2.48161346e-01 2.39411974e+00 9.60686207e-01 9.23370183e-01\n",
      " 7.96277970e-02 8.20808232e-01 1.04817343e+00 1.31065679e+00\n",
      " 5.97612560e-02 4.69038635e-01 6.03622615e-01 3.67351621e-01\n",
      " 4.59508210e-01 1.97869077e-01 5.27934313e-01 1.33428192e+00\n",
      " 2.31193565e-02 6.79126143e-01 4.04469371e-01 5.63521326e-01\n",
      " 1.57297063e+00 2.14331484e+00 6.81224644e-01 1.11155009e+00\n",
      " 7.54709721e-01 1.33028054e+00 1.75198287e-01 6.85080528e-01\n",
      " 1.05054867e+00 7.34260321e-01 3.47372949e-01 1.70651770e+00\n",
      " 6.32914662e-01 1.82908082e+00 1.24950540e+00 9.09591973e-01\n",
      " 5.12648642e-01 5.84123254e-01 4.84859347e-01 1.01685929e+00\n",
      " 1.18302596e+00 1.42234516e+00 4.83946174e-01 8.94332051e-01\n",
      " 2.14968181e+00 4.15047932e+00 8.67481053e-01 1.57453921e-02\n",
      " 1.88273060e+00 2.28948236e+00 2.05883801e-01 1.72829008e+00\n",
      " 6.00011587e-01 8.03619921e-02 1.50697708e+00 9.03668880e-01\n",
      " 1.77635026e+00 4.15969014e-01 2.63008475e-01 5.02972245e-01\n",
      " 6.93989217e-01 9.79414225e-01 2.40530872e+00 1.35077059e+00\n",
      " 7.44699895e-01 1.67976052e-01 1.87946469e-01 1.69356751e+00\n",
      " 1.62476230e+00 2.27264285e-01 4.30816799e-01 1.02529728e+00\n",
      " 1.04530025e+00 2.21680209e-01 2.63967961e-01 1.19326866e+00\n",
      " 1.30100131e+00 1.38987494e+00 6.58936262e-01 1.13875687e-01\n",
      " 9.01341140e-01 3.19671571e-01 1.24004185e+00 3.48760247e-01\n",
      " 8.61883521e-01 1.22929287e+00 5.71931362e-01 5.54426968e-01\n",
      " 3.60828079e-02 9.43267345e-01 7.28826880e-01 2.05687523e+00\n",
      " 8.52928638e-01 3.73319715e-01 7.52109051e-01 2.62320161e-01\n",
      " 2.05870390e+00 1.40248203e+00 1.86646259e+00 5.92468157e-02\n",
      " 1.17348313e+00 2.77012408e-01 6.95689678e-01 7.35134959e-01\n",
      " 5.27881265e-01 1.04214735e-01 3.99042219e-01 1.40601635e+00\n",
      " 4.22620296e-01 1.25386298e+00 1.49914324e-01 1.32241681e-01\n",
      " 1.40397918e+00 8.04323703e-02 1.64901924e+00 1.04820192e-01\n",
      " 7.20329344e-01 2.66749054e-01 6.22102022e-01 9.57669795e-01\n",
      " 1.03108799e+00 4.80827987e-01 1.58042276e+00 3.11528862e-01\n",
      " 4.49607879e-01 1.74874306e+00 9.61561918e-01 1.84735560e+00\n",
      " 6.20247841e-01 9.91896331e-01 1.16890299e+00 3.79641801e-01\n",
      " 8.08927476e-01 1.53043985e+00 1.64628255e+00 8.22255537e-02\n",
      " 2.88231611e-01 3.88075709e-01 6.56061530e-01 2.26159677e-01\n",
      " 1.04751825e+00 9.82071400e-01 3.12227570e-02 2.17449099e-01\n",
      " 4.89104003e-01 9.44545493e-02 2.99688995e-01 8.65965188e-01\n",
      " 2.25527465e-01 1.51800513e+00 1.92432373e-03 3.29002529e-01\n",
      " 3.14587262e-03 2.57181227e-01 1.15340853e+00 1.74457103e-01\n",
      " 2.51785181e-02 4.52043191e-02 2.37225127e+00 3.90316136e-02\n",
      " 3.43227714e-01 3.19649935e+00 6.18366897e-02 3.49888742e-01\n",
      " 1.27655816e+00 1.20491445e+00 1.45148671e+00 3.50247711e-01\n",
      " 9.70404983e-01 7.44535401e-02 7.93228865e-01 2.73534268e-01\n",
      " 2.42971569e-01 1.36301517e+00 1.81814745e-01 5.27978539e-01\n",
      " 4.12201375e-01 1.29289019e+00 1.05690241e+00 8.72368395e-01\n",
      " 4.04580235e-01 2.03040481e+00 1.40174794e+00 9.78060246e-01\n",
      " 1.06394362e+00 7.90443897e-01 9.93025184e-01 7.57922351e-01\n",
      " 8.14277828e-01 1.59736180e+00 9.35668468e-01 8.48092437e-01\n",
      " 1.41385460e+00 1.44358039e+00 3.81564379e-01 1.18735790e+00\n",
      " 1.03081965e+00 3.05598319e-01 1.80514646e+00 2.11392537e-01\n",
      " 1.49662465e-01 3.66858482e+00 7.01273441e-01 1.77480364e+00\n",
      " 1.25465798e+00 2.20050037e-01 2.43550062e+00 1.92372584e+00\n",
      " 8.89839530e-01 1.25994742e+00 1.26500654e+00 1.55677891e+00\n",
      " 7.50126660e-01 6.94532990e-01 7.29584455e-01 5.45471072e-01\n",
      " 1.56109244e-01 8.34097862e-02 8.50131631e-01 2.28954971e-01\n",
      " 6.29192516e-02 1.16075683e+00 1.34174824e+00 9.74219918e-01\n",
      " 1.28949106e-01 4.96924698e-01 4.14855868e-01 1.93409812e+00\n",
      " 6.53078437e-01 3.00466776e-01 2.83942938e+00 3.17195766e-02\n",
      " 4.73891199e-01 1.68907046e-01 8.75809014e-01 1.55180025e+00\n",
      " 1.04092193e+00 9.78986502e-01 2.17194915e+00 1.90010935e-01\n",
      " 4.53855395e-01 4.58088666e-01 2.89318115e-01 1.62915730e+00\n",
      " 1.86943305e+00 1.82986653e+00 2.52845436e-01 1.19058657e+00\n",
      " 1.39481831e+00 8.72891426e-01 2.15246975e-01 2.80778885e-01\n",
      " 9.12189722e-01 1.82313704e+00 1.36963773e+00 9.77290213e-01\n",
      " 1.42707467e+00 1.52763069e+00 7.00778246e-01 9.30190206e-01\n",
      " 3.04177940e-01 3.22533935e-01 1.30852640e+00 5.06159186e-01\n",
      " 5.32375753e-01 1.66051853e+00 1.26262441e-01 7.27833271e-01\n",
      " 5.82841873e-01 1.28494239e+00 1.13310385e-02 2.83806205e+00\n",
      " 1.29651928e+00 1.01996124e+00 1.27222374e-01 7.16018155e-02\n",
      " 6.80025101e-01 2.49314356e+00 3.01615685e-01 1.45706296e+00\n",
      " 2.23825783e-01 4.03623223e-01 2.28742808e-01 8.95551562e-01\n",
      " 8.19017351e-01 4.85058367e-01 1.28386259e+00 1.94284344e+00\n",
      " 5.08028984e-01 1.18622072e-01 5.54022074e-01 1.35334182e+00\n",
      " 1.33090842e+00 1.09570873e+00 5.57451427e-01 1.92839217e+00\n",
      " 6.62981421e-02 1.43032384e+00 8.95088762e-02 1.70233512e+00\n",
      " 5.95149636e-01 2.72465982e-02 7.38461733e-01 5.53394496e-01\n",
      " 1.85569417e+00 1.06255257e+00 7.12502718e-01 2.05886662e-02\n",
      " 6.02818489e-01 6.84559584e-01 4.92500424e-01 3.64859760e-01\n",
      " 4.02911276e-01 9.72714126e-01 3.09534669e+00 2.72073984e-01\n",
      " 1.76641178e+00 1.60776004e-01 8.21515560e-01 8.33937049e-01\n",
      " 3.51049483e-01 5.33918142e-01 1.44331408e+00 1.16933835e+00\n",
      " 1.74701083e+00 9.20650065e-01 1.26484621e+00 1.02223985e-01\n",
      " 9.61409092e-01 6.27947271e-01 1.66593158e+00 1.04139745e+00\n",
      " 1.51909161e+00 3.15595388e-01 4.82360601e-01 3.24906445e+00\n",
      " 1.04036987e-01 5.34575880e-01 1.98453188e+00 5.10715961e-01\n",
      " 7.48448074e-01 3.21080655e-01 6.38008952e-01 5.79882190e-02\n",
      " 4.02852178e-01 8.14949036e-01 9.64411557e-01 8.07609379e-01\n",
      " 8.49569559e-01 2.90602863e-01 2.28192285e-01 1.27842858e-01\n",
      " 1.83431655e-02 6.51152790e-01 1.09628272e+00 6.74830139e-01\n",
      " 1.10243845e+00 2.03696549e-01 5.23773670e-01 1.19635892e+00\n",
      " 4.53709811e-01 1.24511552e+00 1.41816068e+00 1.08715549e-01\n",
      " 1.71520042e+00 5.34076169e-02 1.67359740e-01 2.10111976e+00\n",
      " 1.00389469e+00 8.50258842e-02 5.08192718e-01 3.08748674e+00\n",
      " 8.22804451e-01 1.75075281e+00 2.34917551e-01 1.20755363e+00\n",
      " 1.15478075e+00 1.59359264e+00 9.12052989e-02 8.31095934e-01\n",
      " 1.16513300e+00 6.30489230e-01 9.20778394e-01 1.05018154e-01\n",
      " 7.01518178e-01 1.36447370e+00 4.97496486e-01 2.77232617e-01\n",
      " 5.59697747e-01 1.37114629e-01 1.36575684e-01 6.61109269e-01\n",
      " 1.14201343e+00 4.27094191e-01 7.34362125e-01 1.29609370e+00\n",
      " 2.39352822e+00 8.96892175e-02 1.11723852e+00 6.12499833e-01\n",
      " 1.00481105e+00 9.33201432e-01 4.51704681e-01 1.88597488e+00\n",
      " 9.06457067e-01 4.38229501e-01 2.48994142e-01 1.31206846e+00\n",
      " 7.95955777e-01 1.37888730e+00 3.06371361e-01 1.01319063e+00\n",
      " 8.22295070e-01 5.22438288e-01 6.10808074e-01 2.92630816e+00\n",
      " 9.52063799e-01 3.27291608e-01 1.33536816e+00 5.19630551e-01\n",
      " 8.55192542e-01 9.43833530e-01 5.05771756e-01 2.64035225e+00\n",
      " 1.85238576e+00 2.04163730e-01 7.75814474e-01 1.15697670e+00\n",
      " 2.40819049e+00 1.26007712e+00 2.44395182e-01 4.02690500e-01\n",
      " 2.35818791e+00 1.18337107e+00 3.81615192e-01 1.74947643e+00\n",
      " 1.65381062e+00 2.22359627e-01 1.44049093e-01 2.14923573e+00\n",
      " 9.25429821e-01 2.16956407e-01 8.87319446e-01 5.14424026e-01\n",
      " 2.40218472e+00 1.15969144e-01 8.75475928e-02 1.20000648e+00\n",
      " 1.17188656e+00 4.98403490e-01 1.67033410e+00 1.01219177e+00\n",
      " 1.96936980e-01 7.35063434e-01 1.12619627e+00 3.36456031e-01\n",
      " 2.13680994e-02 3.53610188e-01 4.14097756e-01 5.45067191e-01\n",
      " 3.35864902e+00 1.29430518e-01 1.33402312e+00 5.41621745e-01\n",
      " 6.23918772e-01 5.23298383e-01 1.56284106e+00 1.76881623e+00\n",
      " 1.28425717e+00 2.40733594e-01 6.98882267e-02 1.87192142e+00\n",
      " 6.28418326e-01 6.77231789e-01 8.25162411e-01 5.39847374e-01\n",
      " 8.36327612e-01 1.44405103e+00 1.90250611e+00 1.94515795e-01\n",
      " 5.86696144e-04 1.28142643e+00 1.75650954e+00 2.50439978e+00\n",
      " 2.49673098e-01 1.85632777e+00 4.93569732e-01 1.59136379e+00\n",
      " 6.24528527e-01 1.45100939e+00 9.77472141e-02 6.68671250e-01]\n"
     ]
    }
   ],
   "source": [
    "print(len(clust.labels_))\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdSxc4Dhc-JT"
   },
   "outputs": [],
   "source": [
    "def train5fold(network_configs, model_ft, lr, wd, amsgrad):\n",
    "    folds = ['0', '1', '2', '3', '4']\n",
    "\n",
    "    random_str = str(uuid.uuid4()).split(\"-\")[0]\n",
    "    best_metrics_per_fold = []\n",
    "    model_base = copy.deepcopy(model_ft)\n",
    "    for fold in folds:\n",
    "\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%d-%m-%Y.%H:%M:%S\")\n",
    "        wandb.init(project='hnultra', entity=wandb_username, name=local_username + '_fold_' + fold, group=random_str)\n",
    "        partition = all_folds[fold]\n",
    "\n",
    "        model_ft = copy.deepcopy(model_base)\n",
    "        model_ft = model_ft.to(device)\n",
    "        wandb.watch(model_ft)\n",
    "\n",
    "        # Gather the parameters to be optimized/updated in this run. If we are\n",
    "        #  finetuning we will be updating all parameters. However, if we are\n",
    "        #  doing feature extract method, we will only update the parameters\n",
    "        #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "        #  is True.\n",
    "        params_to_update = model_ft.parameters()\n",
    "        #print(\"Params to learn:\")\n",
    "        if feature_extract:\n",
    "            params_to_update = []\n",
    "            for name,param in model_ft.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    params_to_update.append(param)\n",
    "                    print(\"\\t\",name)\n",
    "        else:\n",
    "            for name,param in model_ft.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(\"\\t\",name)\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer_ft = optim.Adam(params_to_update, lr=lr, weight_decay=wd, amsgrad=amsgrad)\n",
    "\n",
    "        # Setup the loss fxn\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        shuffle = True\n",
    "        num_workers = 6\n",
    "        params = {'batch_size': batch_size,\n",
    "                  'shuffle': shuffle,\n",
    "                  'num_workers': num_workers}\n",
    "\n",
    "        config_dict = {'batch_size': batch_size, 'shuffle': shuffle, 'num_workers': num_workers, 'fold': int(fold),\n",
    "                       'lr': lr, 'wd': wd, 'amsgrad': amsgrad, 'model_name': model_name, 'num_classes': num_classes, \n",
    "                       'num_epochs': num_epochs, 'feature_extract': feature_extract, \"pretrain\": pretrain }\n",
    "\n",
    "        wandb.config.update(config_dict)\n",
    "        wandb.config.update(network_configs)\n",
    "        # Tranforms\n",
    "        trans = transforms.Compose([transforms.RandomAffine(degrees=8, translate=(0.1, 0.1), scale=(0.95,1.25))])\n",
    "\n",
    "        # Generators\n",
    "        training_set = Dataset(partition['train_ids'], partition['train_labels'], transformations=trans)\n",
    "        training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "        validation_set = Dataset(partition['valid_ids'], partition['valid_labels'])\n",
    "        validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "        dataloaders_dict = {'train':training_generator, 'val':validation_generator}\n",
    "\n",
    "        # Train & Evaluate\n",
    "        model_ft, hist, metrics_from_best_epoch = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs, is_inception=(model_name==\"inception\"))\n",
    "        best_metrics_per_fold.append(metrics_from_best_epoch)\n",
    "\n",
    "    # Calculate the performance metrics on the best model in each fold\n",
    "    wandb.init(project='hnultra', entity=wandb_username, name=local_username + '_ALL', group=random_str)\n",
    "    config_dict['fold'] = -1\n",
    "    wandb.config.update(config_dict)\n",
    "    wandb.config.update(network_configs)\n",
    "\n",
    "\n",
    "    metrics_all = {}\n",
    "    for fold in best_metrics_per_fold:\n",
    "        for key in fold:\n",
    "            if key not in metrics_all:\n",
    "                metrics_all[key] = [fold[key]]\n",
    "            else:\n",
    "                metrics_all[key].append(fold[key]) \n",
    "    # print(metrics_all)\n",
    "\n",
    "    metrics_to_log = {}\n",
    "    for m in metrics_all:\n",
    "        metric_list = np.asarray(metrics_all[m])\n",
    "\n",
    "        metrics_to_log[m + '_mean'] = metric_list.mean()    \n",
    "        metrics_to_log[m + '_stdev'] = metric_list.std()\n",
    "\n",
    "    wandb.config.update(metrics_to_log)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07uuFRNNc-JW"
   },
   "outputs": [],
   "source": [
    "def SetupAndRunTest(model_ft, lr, wd, amsgrad, run_configs):\n",
    "    \n",
    "    input_size = 256\n",
    "\n",
    "    # Print the model we just instantiated\n",
    "    print(model_ft)\n",
    "\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model_ft.parameters()\n",
    "#     print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=lr, weight_decay=wd, amsgrad=amsgrad)\n",
    "\n",
    "    # Setup the loss fxn\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv1_filters_size = [8, 16, 32]\n",
    "conv2_filters_size = [16, 32, 8]\n",
    "conv3_filters_size = [32, 16, 8]\n",
    "linear1_sizes = [512, 1024]\n",
    "dropouts = [0.25, 0.3]\n",
    "\n",
    "# lrs = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]\n",
    "# weight_decays = [1e-5, 5e-5, 1e-4, 5e-4, 1e-6, 5e-6]\n",
    "lrs = [5e-4]\n",
    "weight_decays = [1e-3]\n",
    "i = 0\n",
    "amsgrads=[False]\n",
    "for conv1_filters in conv1_filters_size:\n",
    "    for conv2_filters in conv2_filters_size:\n",
    "        for conv3_filters in conv3_filters_size:\n",
    "            for linear1_size in linear1_sizes:\n",
    "                for dropout in dropouts:\n",
    "                    for lr in lrs:\n",
    "                        for wd in weight_decays:\n",
    "                            for amsgrad in amsgrads:\n",
    "                                if i < 0:\n",
    "                                    i += 1\n",
    "                                    continue\n",
    "                                config_string = f\"{conv1_filters}_{conv2_filters}_{conv3_filters}_{linear1_size}_{dropout}_{lr}_{wd}_{amsgrad}\"\n",
    "                                model_ft = ViewNet(num_classes, conv1_filters, conv2_filters, conv3_filters, linear1_size, dropout)\n",
    "                                run_configs = {'lr': lr, 'wd': wd, 'amsgrad': amsgrad,'dropout': dropout, \n",
    "                                              'conv1_filters': conv1_filters, 'conv2_filters': conv2_filters, \n",
    "                                              'conv3_filters': conv3_filters, 'linear1_size': linear1_size }\n",
    "\n",
    "                                train5fold(run_configs, model_ft, lr, wd, amsgrad)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "image_label.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hn",
   "language": "python",
   "name": "hn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
